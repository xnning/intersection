%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:

\documentclass[preprint]{sigplanconf}

\usepackage[utf8]{inputenc}

\input{packages.tex}

%% Those conflicting with the beamer class:

% Already imported in beamer class
% \usepackage[usenames,dvipsnames]{xcolor}

% Already defined in beamer class
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}

\newcommand{\authorNote}[3]{{\color{#2} {\textsc{#1}}: #3}}

\input{macros/pl-theory.tex}
\input{macros.tex}

\title{Coherence}
% \author{Author}
% \date{Date}

\begin{document}
\maketitle

\section{A Section}

In our type-directed translation, some inference rules return conclusions having
\emph{the same constructor}. This phenomenon makes the translation
nondeterministic. As an example,

\begin{lstlisting}
({x=1},,{x=2}).x
\end{lstlisting}

can evaluate to either \lstinline@1@ or \lstinline@2@ (according their
translation in the target language). In this case, the constructor is the
intersection operator, for which both rules, (select1) and (select2), are
applicable.

One remedy, which you may have realised, is to enforce the order of applying
rules. Whenever the case as shown above happens, the right component of
\lstinline@&@ and \lstinline@,,@ will take precedence. In other words, the
(select2) rule is tried first. Only if (select2) fails, the (select1) rule is
tried. Therefore, \lstinline@({x=1},,{x=2}).x@ can only evaluate to 2. Likewise,
\lstinline@({x=1},,{x="hi"}).x@ will evaluate to \lstinline@"hi"@ and will be of
type \lstinline@String@. Generally, three pairs of rules in our system that
cause nondeterminism can all be implemented in the same fashion (sub-and2 is
favored over sub-and1), and (restrict2 is favored over restrict1).

This approach seem works fine until you think about how it interact with
parametric polymorphism. \todo{Not convinced by the example.}

\begin{lstlisting}
(/\A. \(x:A&Int). x) Int (1,,2) + 1
\end{lstlisting}

If we would like to have a deterministic elaboration result, another idea is to
tweak the rules a little bit so that given a term, it is no longer possible that
both of the twin rules described above can be used. For example, if
$\tau_1 \andOp \tau_2 \subtype
\tau_3$, we would like to be certain that either $\tau_1 \subtype
\tau_3$ holds or $\tau_2 \subtype \tau_3$ holds, but not both.

Formally, we can state this theorem as:

\begin{theorem}
  If $\tau_1$, $\tau_2$, $\tau_3$, and $\tau_1 \andOp \tau_2$ are well-formed
  types, and $\tau_1 \andOp \tau_2 \subtype \tau_3$, then $\tau_1 \andOp \tau_3$
  \emph{exclusive} or $\tau_2 \andOp \tau_3$.
\end{theorem}

Note that $A$ \emph{exclusive} or $B$ is true if and only if their truth value
differ. Next, we are going to investigate the minimal requirement (necessary and
sufficient conditions) such that the theorem holds.

If $\tau_1$ and $\tau_2$ in this setting are the same, for example,
$\code{Int} \andOp \code{Int} \subtype \code{Int}$, obviously the theorem will
not hold since both the left $\code{Int}$ and the right $\code{Int}$ are a
subtype of $\code{Int}$.

If our types include primitive subtyping such as
$\code{Nat} \subtype_\text{prim} \code{Int}$ (a natural number is also an
integer), which can be promoted to the normal subtyping with this rule:
\begin{mathpar}
  \inferrule
  {\tau_1 \subtype_\text{prim} \tau_2}
  {\tau_1 \subtype \tau_2}
\end{mathpar}
the theorem will also not hold because
$\code{Int} \andOp \code{Nat} \subtype \code{Int}$ and yet
$\code{Int} \subtype \code{Int}$ and $\code{Nat} \subtype \code{Int}$.

We can try to rule out such possibilities by making the requirement of
well-formedness stronger. This suggests that the two types on the sides of
$\andOp$ should not ``overlap''. In other words, they should be ``disjoint''. It
is easy to determine if two base types are disjoint. For example, $\code{Int}$
and $\code{Int}$ are not disjoint. Neither do $\code{Int}$ and $\code{Nat}$.
Also, types built with different constructors are disjoint. For example,
$\code{Int}$ and $\code{Int} \to \code{Int}$. For function types, disjointness
is harder to visualise. But bear in the mind that disjointness can defined by
the very requirement that the theorem holds.

We shall give two semantics and show the two are the same.

\begin{itemize}
\item an type-directed semantics
\item a direct operational semantics
\end{itemize}

say the example above:

without the cast, you could either get:
1,,'c'
or
1
depending on what rules you use

but I think with your change, you can only get the first

(which is what we want)

let me see how we can get `1` before the change

\begin{mathpar}

\end{mathpar}

% (Int & Char) (1 : Int) ~> 1
% ----------------------------------------------
% (Int & Char) ((1 ,, 'c') : Int & Char) ~> 1

With the change, we need $\code{Int} \subtype \code{Int} \andOp \code{Char}$ to
hold in order to get the premise, which does not. So it can be shown that
$(\code{Int} \andOp \code{Char}) ((1 \mergeOp 'c') : \code{Int} \andOp
\code{Char}) \hookrightarrow 1$ is not derivable.

\end{document}
