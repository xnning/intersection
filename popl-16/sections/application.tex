
\section{Application: Extensibility}
\label{subsec:OAs}

Various solutions to the Expression
Problem~\cite{wadler1998expression} in the
literature~\cite{Swierstra:2008,finally-tagless,oliveira09modular,oliveira2012extensibility,DelawareOS13}
are closely related to type-theoretic encodings of datatypes. Indeed, variants
of the same idea keep appearing in different programming languages,
because the encoding of the idea needs to exploit the particular
features of the programming language (or theorem prover).
Unfortunatelly language-specific constructs obscure the key ideas
behind those solutions.

In this section we show a solution to the
Expression Problem that intends to capture the key ideas of various
solutions in the literature. Moreover, it is shown how \emph{all the
  features} of \namedis (intersection types, the merge operator,
parametric polymorphism and disjoint quantification) are needed to
properly encode one important combinator~\cite{oliveira2013feature} used to compose
multiple operations over datatypes.

\begin{comment}
The combination of parametric polymorphism, intersection types and the
merge operator is useful to encode datatypes with subtyping and
support extensibility in \namedis. The combination of
polymorphism and the merge operator is essential to allow the
composition of multiple operations over datatypes.
In the following
we present a step-by-step solution to the Expression Problem in \namedis,
and illustrate how to combine multiple operations.
\end{comment}

\begin{comment}
Oliveira and Cook~\cite{oliveira2012extensibility} proposed a design pattern that can solve the
Expression Problem in languages like Java. An advantage of the pattern
over previous solutions is that it is relatively lightweight in terms
of type system features. In a latter paper, Oliveira et al.~\cite{oliveira2013feature}
noted some limitations of the original design pattern and proposed
some new techniques that generalized the original pattern, allowing it
to express programs in a Feature-Oriented Programming~\cite{Prehofer97} style.
Key to these techniques was the ability to dynamically compose object
algebras.

Unfortunatelly, dynamic composition of object algebras is
non-trivial. At the type-level it is possible to express the resulting
type of the composition using intersection types. Thus, it is still
possible to solve that part problem nicely in a language like Scala (which
has basic support for intersection types). However, the dynamic
composition itself cannot be easily encoded in Scala. The fundamental
issue is that Scala lacks a \lstinline{merge} operator (see the
discussion in Section~\ref{subsec:interScala}). Although both Oliveira et al.~\cite{oliveira2013feature} and
Rendell et al.~\cite{rendel14attributes} have shown that such a \lstinline{merge} operator can
be encoded in Scala, the encoding fundamentally relies in low-level
programming techniques such as dynamic proxies, reflection or
meta-programming.

Because \namedis supports a \lstinline{merge} operator natively, dynamic
object algebra composition becomes easy to encode. The remainder of
this section shows how object algebras and object algebra composition
can be encoded in \namedis. We will illustrate this point
step-by-step by solving the Expression Problem.
%%Prior knowledge of object algebras is not assumed.
\end{comment}

% can be cumbersome and
% language support for intersection types would solve that problem.
% Our type system is just a simple extension of System $ F $; yet surprisingly, it
% is able to solve the limitations of using object algebras in languages such as
% Java and Scala.

\subsection{Church Encoded Arithmetic Expressions}
In the Expression Problem, the idea is to start with a very simple
system modeling arithmetic expressions and evaluation.
The standard typed Church encoding ~\cite{BoehmBerarducci} for arithmetic expressions,
denoted as the type \lstinline{CExp}, is:

\begin{lstlisting}
type CExp = (*$ \forall $*)E. (Int (*$ \to $*) E) (*$ \to $*) (E (*$ \to $*) E (*$ \to $*) E) (*$ \to $*) E
\end{lstlisting}

\noindent However, as done in various solutions to extensibility, it is better to break
down the type of the Church encoding into two parts:

\begin{lstlisting}
type ExpAlg[E] = {
  lit: Int (*$ \to $*) E,
  add: E (*$ \to $*) E (*$ \to $*) E
} in (*$ \ldots $*)
\end{lstlisting}

\noindent The first part, captured by the type \lstinline{ExpAlg[E]}
is constitutes the so-called algebra of the datatype. For additional
clarity of presentation, records (supported in the implementation of \namedis)
are used to capture the two components of the algebra.
The first component abstracts over the type of the
constructor for literal expressions ($\tyint \to E$). The second
component abstracts over the type of addition expressions
($E \to E \to E$).

The second part, which is the actual type of the Church encoding, is:

\begin{lstlisting}
type Exp = { accept: (*$ \Lambda $*)E. ExpAlg[E] (*$ \to $*) E } in (*$ \ldots $*)
\end{lstlisting}

\noindent It should be clear that, modulo some refactoring, and the
use of records, the type \lstinline{Exp} and \lstinline{CExp}
are equivalent.

\paragraph{Data constructors.}
Using \lstinline{Exp} the two data constructors are defined as follows:

\begin{lstlisting}
let lit (n: Int): Exp = {
  accept = (*$ \Lambda $*)E (*$ \to $*) fun (f: ExpAlg[E]) (*$ \to $*) f.lit n
} in
let add (e1: Exp) (e2: Exp): Exp = {
  accept = (*$ \Lambda $*)E (*$ \to $*) fun (f: ExpAlg[E]) (*$ \to $*)
   f.add (e1.accept[E] f) (e2.accept[E] f)
} in
(*$ \ldots $*)
\end{lstlisting}

Note that the notation \lstinline{/\E} in the definition of the
\lstinline{accept} fields is a type abstraction: it
introduces a type variable in the environment. The definition of the
constructors themselves follows the usual Church encodings.

Simple expressions, can be built using the data constructors:

\begin{lstlisting}
let five : Exp = add (lit 3) (lit 2) in (*$ \ldots $*)
\end{lstlisting}

\paragraph{Operations.} Defining operations over expressions requires
implementing \lstinline{ExpAlg[E]}. For example, an interesting
operation over expressions is evaluation. The first step is to define
the evaluation operation is to chose how to instantiate the type
parameter \lstinline{E} in \lstinline{ExpAlg[E]} with a suitable
concrete type for evaluation. One such suitable type is:

\begin{lstlisting}
type IEval = { eval: Int } in (*$ \ldots $*)
\end{lstlisting}

\noindent Using \lstinline{IEval}, a record \lstinline{evalAlg}
implementing \lstinline{ExpAlg} is defined as follows:

\begin{lstlisting}
let evalAlg: ExpAlg[IEval] = {
  lit = fun (x: Int) (*$ \to $*) { eval = x },
  add = fun (x: IEval) (y: IEval) (*$ \to $*) {
    eval = x.eval + y.eval
  }
} in (*$ \ldots $*)
\end{lstlisting}

In this record, the two operations
\lstinline{lit} and \lstinline{add} return a record with type
\lstinline{IEval}. The definition of \lstinline{eval} for
\lstinline{lit} and \lstinline{add} is straightforward.


%The type \lstinline$ExpAlg[IEval]$ is the type of object algebras
%supporting evaluation.
%However, the one interesting point
%of object algebras is that other operations can be supported as
%well.

Using \lstinline{evalAlg}, the expression \lstinline{five} can
be evaluated as follows:

\begin{lstlisting}
(five.accept[IEval] evalAlg).eval
\end{lstlisting}

\subsection{Extensibility and Subtyping} Of course, in the Expression
Problem the goal is to achieve extensibility in two dimensions: constructors and operations.
Moreover, in the presence of subtyping it is also interesting to see how the extended datatypes
relate to the original datatypes. We discuss the two topics next.

\paragraph{New constructors.} Here is the code needed to add a new subtraction constructor:
%Arithmetic expressions with subtyping are defined using the type \lstinline{SubExp}:

\begin{lstlisting}
type SubExpAlg[E] = ExpAlg[E] & { sub: E (*$ \to $*) E (*$ \to $*) E } in
type SubExp = { accept: (*$ \forall $*)A (*$ \to $*) SubExpAlg[A] (*$ \to $*) A } in
let sub (e1: SubExp) (e2: SubExp): SubExp = {
  accept = (*$ \Lambda $*)E (*$ \to $*) fun (f : SubExpAlg[E]) (*$ \to $*)
  f.sub (e1.accept[E] f) (e2.accept[E] f)
} in
(*$ \ldots $*)
\end{lstlisting}

\noindent Firstly \lstinline{SubExpAlg} defines an extended algebra
that contains the constructors of \lstinline{ExpAlg} plus the new
subtraction constructors. Intersection types are used to do the type
composition. Secondly, a new type of expressions with subtraction
(\lstinline{SubExp}) is needed. For \lstinline{SubExp} it is important
that the \lstinline{accept} field now takes an algebra of type
\lstinline{SubExpAlg} as argument. This is necessary to define the
constructor for subtraction (\lstinline{sub}), which requires the
algebra to have the field \lstinline{sub}.


\paragraph{Extending existing operations.} In order to use evaluation
with the new type of expressions, it is necessary to also extend
evaluation. Importantly, extension is achieved using the merge operator:

\begin{lstlisting}
let subEvalAlg = evalAlg ,, {
  sub = fun (x: IEval) (y: IEval) (*$ \to $*) {
    eval = x.eval - y.eval
  }
} in (*$ \ldots $*)
\end{lstlisting}

\noindent In the code, the merge operator takes \lstinline{evalAlg}
and a new record with the implementation of evaluation for
subtraction, to define the implementation for arithmetic expressions
with subtraction.

\paragraph{Subtyping.} In the presence of subtyping, there are
interesting subtyping relations between datatypes and their
extensions~\cite{oliveira09modular}.  Such subtyping relations are usually not
discussed in theoretical treatments of Church encodings. This is
probably partly due to most work on typed Church encodings being
done in calculi without subtyping.

The interesting aspect about subtyping in typed Church encodings is
that subtyping follows the opposite direction of the extension.  In
other words subtyping is contravariant with respect to the
extension. Such contravariance is explained by the type of the
\lstinline{accept} field, which is a function where the argument type
is refined in the extensions. Thus, due to the contravariance of
subtyping on functions, the extension becomes a supertype of the
original datatype.

In the particular case of expressions \lstinline{Exp} (the original and smaller
datatype) is a subtype of \lstinline{SubExp} (the larger and extended
datatype). Because of this subtyping relation, writting the following
expression is valid in \namedis:

\begin{lstlisting}
let three : SubExp = sub five (lit 2)
\end{lstlisting}

\noindent Note the \lstinline{three} is of type \lstinline{SubExp},
but the first argument (\lstinline{five}) to the constructor
\lstinline{sub} is of type \lstinline{Exp}. This can only type-check
if \lstinline{Exp} is indeed a subtype of \lstinline{SubExp}.





\paragraph{New operations.}
The second type of extension is adding a new operation, such as pretty printing.
Similarly to evaluation, the interface of the pretty printing feature
is modeled as:
\begin{comment}
  \begin{lstlisting}
    type IPrint = { print : String } in (*$ \ldots $*)
  \end{lstlisting}
\end{comment}
\begin{lstlisting}
type IPrint = { print: String } in (*$ \ldots $*)
\end{lstlisting}
The implementation of pretty printing for expressions that support literals,
addition, and subtraction is:

\begin{lstlisting}
let printAlg: SubExpAlg[IPrint] = {
  lit = fun (x: Int) (*$ \to $*) {
    print = x.toString()
  },
  add = fun (x: IPrint) (y: IPrint) (*$ \to $*) {
    print = x.print ++ " + " ++ y.print
  },
  sub = fun (x: IPrint) (y: IPrint) (*$ \to $*) {
    print = x.print ++ " - " ++ y.print
  }
} in (*$ \ldots $*)
\end{lstlisting}

\noindent The definition of \lstinline{printAlg} is unremarkable.
With \lstinline{printAlg} we can pretty print the expression represented
by \lstinline{three}:

\begin{lstlisting}
(three.accept[IPrint] printAlg).print
\end{lstlisting}

\begin{comment}
The result is \lstinline$"7 - 2"$. Note that the programmer is able to pass \lstinline{lit 2}, which is of type \lstinline{Exp},
to \lstinline{sub}, which expects a \lstinline{SubExp}. The types are compatible
because because \lstinline$Exp$ is a \emph{subtype} of \lstinline$SubExp$. Code
reuse is achieved since we can use the constructors from \lstinline$Exp$ as the
constructor for \lstinline$SubExp$. In Scala, we would have to define two
literal constructors, one for \lstinline$Exp$ and another for
\lstinline$SubExp$.
\end{comment}

\subsection{Composition of Algebras}
The final example shows a non-trivial combinator for algebras that
allows multiple algebras to be combined into one. A version of this
combinator has been encoded in Scala before using intersection types
(which Scala supports) and an encoding of the merge
operator~\cite{oliveira2013feature,rendel14attributes}.
Unfortunatelly, the Scala encoding of the merge operator is quite complex as
it relies on low-level type-unsafe programming features such as
dynamic proxies, reflection or other meta-programming techniques.
In \namedis there is no need for such hacky encoding, as the
merge operator is nativelly supported. Therefore the combinator for
composing algebras is implemented much more elegantly.
The combinator is defined by the \lstinline$combine$ function, which takes two object algebras to create
a combined algebra. It does so by constructing a new algebra
where each field is a function that delegates the input to the two
algebra parameters.

\begin{lstlisting}
let combine (*$ \alpha $*) ((*$ \beta $*) * (*$ \alpha $*)) (f: ExpAlg[(*$ \alpha $*)]) (g: ExpAlg[(*$ \beta $*)]) :
  ExpAlg[(*$ \alpha $*) & (*$ \beta $*)] = {
    lit = fun (x: Int) (*$ \to $*) f.lit x ,, g.lit x,
    add = fun (x: (*$ \alpha $*) & (*$ \beta $*)) (y: (*$ \alpha $*) & (*$ \beta $*)) (*$ \to $*)
      f.add x y ,, g.add x y
}
\end{lstlisting}

Note how \lstinline{combine} requires all the interesting
features of \namedis. Parametric polymorphism is needed because
\lstinline{combine} must compose algebras with arbitrary type
parameters. Intersection types are needed because the resulting
algebra will create values with an intersection type composing
the two type parameters of the two input algebras. The merge operator
is needed to compose the results of each algebra together. Finally,
a disjointness constraint is needed to ensure that the two input
algebras build values of disjoint types (otherwise ambiguity could
arize).

With \lstinline{combine} printing and evaluation of expressions with
subtraction is done as follows:

\begin{lstlisting}
let newAlg: ExpAlg[IEval&IPrint] =
    combine[IEval,IPrint] evalAlg printAlg in
let o = five.accept[IEval&IPrint] newAlg in
o.print ++ " = " ++ o.eval.toString()
\end{lstlisting}

Note that \lstinline$o$ is a value that supports both
evaluation and printing. The final expression uses \lstinline{o}
for doing both printing and evaluation.
