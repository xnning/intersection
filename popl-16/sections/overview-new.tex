\section{Overview} \label{sec:overview}

This section introduces \name and its support for intersection types,
parametric polymorphism and the merge operator. It then discusses
the issue of coherence and shows how the notion of disjoint
intersection types and disjoint quantification achieve a coherent semantics.
Finally we illustrate the expressive power of \name by encoding 
extensible type-theoretic encodings of datatypes.

Note that this section uses some syntactic sugar, as well as standard
programming language features, to illustrate the various concepts in
\name. Although the minimal core language that we formalize in
Section~\ref{sec:fi} does not present all such features, our implementation
supports them.

\bruno{Need to type-check the programs!}
\bruno{Need to make code formatting homogeneous!}


\begin{comment}
It then shows that,
with unrestricted intersection types, the system
lacks \emph{coherence}. This motivates the introduction of
disjoint intersection types and extending universal quatification to
disjoint quantification, which is enough to ensure coherence.
\end{comment}

\subsection{Intersection Types and the Merge Operator}
%%\subsection{Intersection Types, Merge and Polymorphism in \name}

Intersection types date back as early as Coppo et
al.'s work~\cite{coppo1981functional}. Since then various researchers have
studied intersection types, and some languages have adopted them in one
form or another. 
%However, as we shall see in
%Section~\ref{subsec:incoherence}, it also introduces difficulties. In what follows 
%intersection types and the merge operator are informally introduced.

\paragraph{Intersection Types}
The intersection of type $A$ and $B$ (denoted as \lstinline{A & B} in
\name) contains exactly those values
which can be used as either of type $A$ or of type $B$. For instance,
consider the following program in \name:

\begin{lstlisting}
let x : Int & Char = ...;  -- definition ommitted
let idInt (y : Int) : Int = y;
let idChar (y : Char) : Char = y;
(idInt x, idChar x)
\end{lstlisting}

\noindent If a value \lstinline{x} has type \lstinline{Int & Char} then
\lstinline{x} can be used as an integer or as a character. Therefore,
\lstinline{x} can be used as an argument to any function that takes
an integer as an argument, or any
function that take a character as an argument. In the program above
the functions \lstinline{idInt} and \lstinline{idChar} are the
identity functions on integers and characters, respectively. 
Passing \lstinline{x} as an argument to either one (or both) of the
functions is valid.

\paragraph{Merge Operator}
In the previous program we deliberatly did not show how to introduce values of an
intersection type. There are many variants of intersection types
in the literature. Our work follows a particular formulation, where
intersection types are introduced by a \emph{merge operator}. 
As Dunfield~\cite{dunfield2014elaborating} has argued a merge operator adds considerable
expressiveness to a calculus. The merge operator allows
two values to be merged in a single intersection type. For example, an
implementation of \lstinline{x} is constructed in \name as follows:

\begin{lstlisting}
let x : Int & Char = 1 ,, 'c';
\end{lstlisting}

\noindent In \name (following Dunfield's notation), the
merge of two values $v_1$ and $v_2$ is denoted as $v_1 ,, v_2$.

\paragraph{Merge Operator and Pairs}
The merge operator is similar to the introduction construct on pairs.
An analogous implementation of \lstinline{x} with pairs would be:

\begin{lstlisting}
let xPair : (Int, Char) = (1, 'c');
\end{lstlisting}

\noindent The significant difference between intersection types with a
merge operator and pairs is in the elimination construct. With pairs
there are explicit eliminators (\lstinline{fst} and
\lstinline{snd}). These eliminators must be used to extract the
components of the right type. For example, in order to use
\lstinline{idInt} and \lstinline{idChar} with pairs, we would need to
write a program such as:

\begin{lstlisting}
(idInt (fst xPair), idChar (snd xPair))
\end{lstlisting}

\noindent In contrast the elimination of intersection types is done
implicitly, by following a type-directed process. For example,
when a value of type \lstinline{Int} is needed, but an intersection
of type \lstinline{Int & Char} is found, the compiler uses the
type system to extract the corresponding value.

\subsection{Incoherence}\label{subsec:incoherence}
Unfortunatelly the implicit nature of elimination for intersection
types built with a merge operator can lead to incoherence.
The merge operator combines two terms, of type $A$ and $B$
respectively, to form a term of type $A \inter B$. For example,
$1 \mergeop `c'$ is of type $\tyint \inter \tychar$. In this case, no
matter if $1 \mergeop `c'$ is used as $\tyint$ or $\tychar$, the result
of evaluation is always clear. However, with overlapping types, it is
not straightforward anymore to see the result. For example, what
should be the result of this program, which asks for an integer out of
a merge of two integers:
\[ \app {(\lambda (x : \tyint). x)} {(1 \mergeop 2)} \]
Should the result be $1$ or $2$?

If both results are accepted, we say that the semantics is
\emph{incoherent}: there are multiple possible meanings for the same
valid program. Dunfield's calculus~\cite{dunfield2014elaborating} is incoherent and accepts the
program above.

\paragraph{Getting Around Incoherence: Biased Choice}
In a real implementation of Dunfield calculus a choice has to be made
on which value to compute. For example, one potential option is to
take either always take the left-most value matching the type in the
merge. Similarly, one could take always take the right-most
value matching the type in the merge. Either way, the meaning
of a program will always depend on a biased implementation choice, 
which is clearly unsatisfying from the theoretical point of view
(although perhaps acceptable in practice).
Moreover, even if it accept a particular biased choice as
being good enough, the approach cannot be easily
extended to systems with parametric polymorphism, as we illustrate 
in Section~\ref{subsec:polymorphism}.

\subsection{Restoring Coherence: Disjoint Intersection Types}\label{sec:restoring}
Coherence is a desirable property for a semantics. A semantics is said
to be coherent if any \emph{valid program} has exactly one
meaning~\cite{Reynolds:1991} (that is, the semantics is not ambiguous).
One option to restore coherence is to reject programs which may have
multiple meanings.
%Of course, when rejecting programs it is important
%not to be too conservative, and reject too many programs which are
%actually coherent.
Analysing the expression $1 \mergeop 2$, we can see that the reason
for incoherence is that there are multiple, overlapping, integers in the
merge. Generally speaking, if both terms can be assigned some type $C$,
both of them can be chosen as the meaning of the merge,
which leads to multiple meanings of a term.
Thus a natural option is to try to forbid such overlapping
values of the same type in a merge.

This is precisely the approach taken in \name. \name requires that the
two types of in intersection must be \emph{disjoint}.  However,
although disjointness seems a natural restriction to impose on
intersection types, it is not obvious to formalize it. Indeed Dunfield
has mentioned disjointness as an option to restore coherence, but he
left it for future work due to the non-triviality of the approach.

\paragraph{Searching for a Definition of Disjointness}
The first step towards disjoint intersection types is to come up
with a definition of disjointness. A first attempt at such definition would
be to require that, given two types $A$ and $B$, both types are not
subtypes of each other. Thus, denoting disjointness as $A * B$, we would have:
\[A * B \equiv A \not<: B \wedge B \not<: A\]
At first sight this seems a reasonable definition and it does prevent
merges such as \lstinline{1 ,, 2}. However some moments of thought are enough to realize that
such definition does not ensure disjointness. For example, consider
the following merge:

\begin{lstlisting}
((1 ,, 'c') ,, (2 ,, True))
\end{lstlisting}

\noindent This merge has two components which are also intersection
types. The first component (\lstinline{(1,,'c')}) has type $\tyint \inter
\tychar$, whereas the second component (\lstinline{(2 ,, True)}) has type
$\tyint \inter \tybool$. Clearly,
\[ \tyint \inter \tychar \not \subtype \tyint \inter \tybool \wedge \tyint \inter \tybool \not \subtype \tyint \inter \tychar \]
Nevertheless the following program still leads to
incoherence:
\[ \app {(\lamty x \tyint x)} {((1 \mergeop 'c') \mergeop (2 \mergeop \code{True}))} \]
as both \lstinline{1} or \lstinline{2} are possible outcomes
of the program. Although this attempt to define disjointness failed,
it did bring us some additional insight: although the types of the two
components of the merge are not subtypes of each other, they share
some types in common.

\paragraph{A Proper Definition of Disjointness} In order for two types
to be trully disjoint, they must not have any subcomponents sharing
the same type. In a system with intersection types this can be ensured
by requiring the two types do not share a common supertype. The
following definition captures this idea more formally.

\begin{definition}[Disjointness]
  Given two types $A$ and $B$, two types are disjoint
  (written $A \disjoint B$) if there is no type $C$ such that both $A$ and $B$ are
  subtypes of $C$:
  \[A \disjoint B \equiv \not\exists C.~A \subtype C \wedge B \subtype C\]
\end{definition}

\noindent This definition of disjointness prevents the problematic
merge. Since $Int$ is a common supertype of both $Int \& Char$ and
$Int \& Bool$, those two types are not disjoint.

\name's type system only accepts programs that use disjoint
intersection types. As shown in Section~\ref{sec:disjoint} disjoint intersection
types will play a crutial rule in guaranteing that the semantics is coherent.

\subsection{Parametric Polymorphism and Intersection Types}\label{subsec:polymorphism}
Before we show how \name extends the idea of disjointness to parametric 
polymorphism, we discuss some non-trivial issues that arize from 
the interaction between parametric polymorphism and intersection types. 
%The interaction between parametric polymorphism and
%intersection types when coherence is a goal is non-trivial. 
%In particular biased choice . 
%The key challenge is to have a type
%system that still ensures coherence, but at the same time is not too
%restrictive in the programs that can be accepted. 
\begin{comment}
Dunfield~\cite{} provides a
good illustrative example of the issues that arize when combining
disjoint intersection types and parametric polymorphism:
\[\lambda x. {\bf let}~y = 0 \mergeop x~{\bf in}~x\]
\end{comment}
Consider the attempt to write 
the following polymorphic function in \name:
\[{\bf let}~fst~A~B~(x : A \& B) = (\lambda z : A. z)~x;\] The
\code{fst} function is supposed to extract a value from the merge that
matches the type of the first type parameter (\lstinline{A}).  However
this function is problematic.  The reason is that when
\lstinline{A} and \lstinline{B} are instantiated to non-disjoint
types, then uses of \lstinline{fst} may lead to incoherence.
For example, consider the following use of \lstinline{fst}:
\[fst~Int~Int~(1,,2)\]
\noindent This program is clearly incoherent as both 
$1$ and $2$ can be extracted from the merge and still match the type
of the first argument of \lstinline{fst}.

\paragraph{Biased Choice Breaks Equational Reasoning} At first sight, one option 
to workaround the issue incoherence would be to bias the type-based merge lookup 
to the left or to the right (as discussed in
Section~\ref{subsec:incoherence}). Unfortunatelly, biased choice is
very problematic when parametric polymorphism is present in the language.
To see the issue, suppose we chose to always pick the
rightmost value in a merge when multiple values of same type exist.
Intuitively, it would appear that the result of the use of
\lstinline{fst} above is $2$. Indeed simple equational reasoning
seems to validate such result:

\vspace{5pt}
\noindent$fst~Int~Int~(1,,2)$\\
$\equiv\{\text{definition of}~fst\}$\\
$(\lambda (z : Int). z) (1,,2)$\\
$\equiv\{\text{implicit coercion (biased to the right)}\}$\\
$(\lambda (z : Int). z)~2$\\
$\equiv\{\beta\text{-reduction}\}$\\
$2$
\vspace{5pt}

However (assumming a straightforward implementation of right-biased
choice) the result of the program would be 1! The reason for this has
todo with \emph{when} the type-based lookup on the merge happens. In
the case of \lstinline{fst}, lookup is triggered by a coercion
function inserted in the definition of \lstinline{fst} at
compile-time. 
In the definition of $fst$ all it is known is that a
value of type $A$ should be returned from a merge with an intersection
type $A\&B$.  Clearly the only type-safe choice to coerce the value of
type $A\&B$ into $A$ is to
take the left component of the merge. This works perfectly for merges
such as $(1,,'c')$, where the types of the first and second components
of the merge are disjoint. For the merge $(1,,'c')$, if a integer lookup 
is needed, then $1$ is the rightmost integer, which is consistent with the 
biased choice. Unfortunatelly, when given the merge $(1,,2)$ the 
left-component ($1$) is also picked up, even though in this case $2$
is the rightmost integer in the merge. Clearly this is inconsistent 
with the biased choice!

Unfortunatelly this subtle interaction of polymorphism and type-based lookup
 means that equational reasoning is broken!
In the equational reasoning steps above, doing apparently correct
substitutions lead us to a wrong result. This is a major problem for
biased choice and a reason to dismiss it as a possible implementation
choice for \name.

\paragraph{Conservatively Rejecting Intersections}
To avoid incoherence, and the issues of biased choice, another option 
is simply to reject programs where the
instantiations of type variables may lead to incoherent programs. 
In this case the definition of $fst$ would be rejected, since there
are indeed some cases that may lead to incoherent programs. 
Unfortunatelly this is too restrictive and prevents many useful
programs using both parametric polymorphism and intersection types.
In particular, in the case of \lstinline{fst}, if the two type
parameters are used with two disjoint intersection
types, then the merge will not lead to ambiguity. 

In summary, it seems hard to have parametric polymorphism, intersection 
types and coherence without being overly conservative. 


\begin{comment}
\subsection{Intersection Types in Existing Languages}

What is an intersection type? The intersection of types $A$ and $B$
contains exactly those values which can be used as either of type $A$
or of type $B$.  Just as not all intersection of sets are nonempty,
not all intersections of types are inhabited.  For example, the
intersection of a base type $\tyint$ and a function type
$\tyint \to \tyint$ is not inhabited.\bruno{put this text somewhere?}

Since then various researchers have
studied intersection types, and some languages have adopted in one
form or another. However, while intersection types are already used
in various languages, the lack of a merge operator removes
considerable expressiveness.


A number of OO languages, such as
Java, C\#, Scala, and Ceylon\footnote{\url{http://ceylon-lang.org/}},
already support intersection types to different degrees. Intersection
types are particularly relevant for OOP as they can be used to model
multiple interface inheritance. In Java, for example,

\begin{lstlisting}
interface AwithB extends A, B {}
\end{lstlisting}

\noindent introduces a new interface \lstinline{AwithB} that satisfies the interfaces of
both \lstinline{A} and \lstinline{B}. Arguably such type can be considered as a nominal
intersection type. Scala takes one step further by eliminating the
need of a nominal type. For example, given two concrete traits, it is possible to
use \emph{mixin composition} to create an object that implements both
traits. Such an object has a (structural) intersection type:

\begin{lstlisting}
trait A
trait B

val newAB : A with B = new A with B
\end{lstlisting}

\noindent Scala also allows intersection of type parameters. For example:
\begin{lstlisting}
def merge[A,B] (x: A) (y: B) : A with B = ...
\end{lstlisting}
uses the annonymous intersection of two type parameters \lstinline{A} and
\lstinline{B}. However, in Scala it is not possible to dynamically
compose two objects. For example, the following code:

\begin{lstlisting}
// Invalid Scala code:
def merge[A,B] (x: A) (y: B) : A with B = x with y
\end{lstlisting}

\noindent is rejected by the Scala compiler. The problem is that the
\lstinline{with} construct for Scala expressions can only be used to
mixin traits or classes, and not arbitrary objects. Note that in the
definition \lstinline{newAB} both \lstinline{A} and \lstinline{B} are
\emph{traits}, whereas in the definition of \lstinline{merge} the variables
\lstinline{x} and \lstinline{y} denote \emph{objects}.

This limitation essentially put intersection types in Scala in a second-class
status. Although \lstinline{merge} returns an intersection type, it is
hard to actually build values with such types. In essense an
object-level introduction contruct for intersection types is missing.
As it turns out using low-level type-unsafe programming features such
as dynamic proxies, reflection or other meta-programming techniques,
it is possible to implement such an introduction
construct in Scala~\cite{oliveira2013feature,rendel14attributes}. However, this
is clearly a hack and it would be better to provide proper language
support for such a feature.




\paragraph{Parametric Polymorphism and Intersection Types}
Both universal quantification and intersection types provide a kind of
polymorphism. While the former provides parametric polymorphism, the latter
provides ad-hoc polymorphism. In some systems, parametric polymorphism is
considered the infinite analog of intersection polymorphism. But in our system
we do not consider this relationship. \george{Need to argue that why their
coexistence might be a good thing.} \george{May use the merge example}
\bruno{Some more examples in following subsections?}


To address the limitations of intersection types in languages like
Scala, \name allows intersecting any two terms at run time using a
\emph{merge} operator (denoted by $ \mergeop $)~\cite{dunfield2014elaborating}.  With the merge
operator it is trivial to implement the \lstinline{merge} function in \name:

\begin{lstlisting}
let merge[A, B * A] (x : A) (y : B) : A & B = x ,, y;
\end{lstlisting}

\noindent In contrast to Scala's term-level \lstinline{with}
construct, the operator \lstinline{,,} allows two arbitrary values \lstinline{x}
and \lstinline{y} to be merged. The resulting type is a \emph{disjoint}
intersection of the types of  \lstinline{x}
and \lstinline{y} (\lstinline{A & B} in this case).

\paragraph{Incoherence and Parametric Polymorphism}
We can define a \code{fst} function that extracts the first item of a merged value:
\[
\code{fst} \ \alpha \ \beta \ (x : \alpha \inter \beta) = \app {(\lam y \alpha y)} x
\]
What should be the result of this program?
\begin{lstlisting}
fst Int Int (1,,2)
\end{lstlisting}

Then we have the following equational reasoning:
\begin{lstlisting}
fst Int Int (1,,2) => (\(y : Int). y) (1,,2)
\end{lstlisting}
If we favour the second item, the program seems to evaluate to $2$. But in
reality, the result is $2$. No matter we favour the first or the second item,
we can always construct a program such that for that program, equational
reasoning is broken.

Therefore, we require that the two types of an intersection must be not
overlapping, or \emph{disjoint}, and add this requirement to the well-formedness of types.

A well-formed type is such that given any query type,
it is always clear which subpart the query is referring to.
In terms of rules, this notion of well-formedness is almost the same as the one in System $F$
except for intersection types we require the two components to be disjoint.

With parametric polymorphism, disjointness is harder to determine due to type variables.
Consider this program:
\[
\blam \alpha {\lam x {\alpha \inter \tyint} x}
\]
$x$ in the body is of type $\alpha \inter \tyint$ and if $\alpha$ and $\tyint$ are
disjoint depends on the instantiation of $\alpha$.
\end{comment}

\subsection{Disjoint Quantification}
To avoid being overly conservative, while still retaining coherence in the 
presence of parametric polymorphism and intersection types, \name uses 
an extension to universal quantification called \emph{disjoint quantification}. 
Inspired by
bounded quantification~\cite{Cardelli:1994}, 
where a type variable is constrained by a type
bound, disjoint quantification allows a type variable to be
constrained so that it is disjoint with a
given type. With disjoint quantification a variant of the program $fst$, which
is accepted by \name, would be written as:
\[{\bf let}~fst~A~(\fcolorbox{light-gray}{light-gray}{B*A})~(x : A \& B) = (\lambda z : A. z)~x;\]
The small change is in the declaration of the type parameter $B$. The notation 
$B*A$ means that in this program the type variable $B$ is constrained so that 
it can only be instantiated with any type disjoint to $A$. 
This ensures that the
merge denoted by $x$ is disjoint for all valid instantiations of $A$ and $B$.

The nice thing about this solution is that many uses of $fst$ are accepted. 
For example, the following use of $fst$:
\[fst~Int~Char~(1,,'c')\]
is accepted since $Int$ and $Char$ are disjoint, thus satisfying the constraint 
on the second type parameter of $fst$.
However, problematic uses of $fst$ are rejected. For example:
\[fst~Int~Int~(1,,2)\]
is rejected because $Int$ is not disjoint with $Int$, thus failing to satisfy the 
disjointness constraint on the second type parameter of $fst$.

\begin{comment}
Note that there is a nice symmetry between bounded quantification and disjoint quantification.
In systems with bounded quantification,
the usual unconstrained quantifier $\for {\alpha} \ldots$
is a syntactic sugar for $\for {\alpha \subtype \top} \ldots$, and
$\blam \alpha \ldots$ for $\blam {\alpha \subtype \top} \ldots$.
In parellel, in our system with disjoint quantification,
the usual unconstrained quantifier $\for {\alpha} \ldots$
is a syntactic sugar for $\for {\alpha \disjoint \bot} \ldots$, and
$\blam \alpha \ldots$ for $\blam {\alpha \disjoint \top} \ldots$.
The intuition is that since the bottom type is akin to the empty set,
no other type overlaps with it.\george{Format this paragraph better.}
\end{comment}


\begin{comment}
With this tool in hand, we can rewrite the program above to:
\[
\blam {\alpha \disjoint \tyint} {\lam x {\alpha \inter \tyint} x}
\]

This program typechecks because while $x$ is of type $\alpha \inter \tyint$,
and $\alpha$ is disjoint with $\tyint$. Similarly, in the new system,
the original program no longer typechecks, thus preventing overlapping types.
\end{comment}

\section{Application: Extensibility}
\label{subsec:OAs}

Various solutions to the Expression
Problem~\cite{wadler1998expression} in the 
literature~\cite{Swierstra:2008,finally-tagless,oliveira09modular,oliveira2012extensibility,DelawareOS13}
are closely related to type-theoretic encodings of datatypes. Indeed, variants 
of the same idea keep appearing in different programming languages,
because the encoding of the idea needs to exploit the particular
features of the programming language (or theorem prover). 
Unfortunatelly language-specific constructs obscure the key ideas
behind those solutions. 

In this section we show a solution to the
Expression Problem that intends to capture the key ideas of various
solutions in the literature. Moreover, it is shown how \emph{all the
  features} of \name (intersection types, the merge operator,
parametric polymorphism and disjoint quantification) are needed to
properly encode one important combinator~\cite{oliveira2013feature} used to compose
multiple operations over datatypes.

\begin{comment}
The combination of parametric polymorphism, intersection types and the
merge operator is useful to encode datatypes with subtyping and
support extensibility in \name. The combination of
polymorphism and the merge operator is essential to allow the
composition of multiple operations over datatypes. 
In the following
we present a step-by-step solution to the Expression Problem in \name,
and illustrate how to combine multiple operations.
\end{comment}

\begin{comment}
Oliveira and Cook~\cite{oliveira2012extensibility} proposed a design pattern that can solve the
Expression Problem in languages like Java. An advantage of the pattern
over previous solutions is that it is relatively lightweight in terms
of type system features. In a latter paper, Oliveira et al.~\cite{oliveira2013feature}
noted some limitations of the original design pattern and proposed
some new techniques that generalized the original pattern, allowing it
to express programs in a Feature-Oriented Programming~\cite{Prehofer97} style.
Key to these techniques was the ability to dynamically compose object
algebras.

Unfortunatelly, dynamic composition of object algebras is
non-trivial. At the type-level it is possible to express the resulting
type of the composition using intersection types. Thus, it is still
possible to solve that part problem nicely in a language like Scala (which
has basic support for intersection types). However, the dynamic
composition itself cannot be easily encoded in Scala. The fundamental
issue is that Scala lacks a \lstinline{merge} operator (see the
discussion in Section~\ref{subsec:interScala}). Although both Oliveira et al.~\cite{oliveira2013feature} and
Rendell et al.~\cite{rendel14attributes} have shown that such a \lstinline{merge} operator can
be encoded in Scala, the encoding fundamentally relies in low-level
programming techniques such as dynamic proxies, reflection or
meta-programming.

Because \name supports a \lstinline{merge} operator natively, dynamic
object algebra composition becomes easy to encode. The remainder of
this section shows how object algebras and object algebra composition
can be encoded in \name. We will illustrate this point
step-by-step by solving the Expression Problem.
%%Prior knowledge of object algebras is not assumed.
\end{comment}

% can be cumbersome and
% language support for intersection types would solve that problem.
% Our type system is just a simple extension of System $ F $; yet surprisingly, it
% is able to solve the limitations of using object algebras in languages such as
% Java and Scala.

\subsection{Church Encoded Arithmetic Expressions}
In the Expression Problem, the idea is to start with a very simple
system modeling arithmetic expressions and evaluation.
The standard typed Church encoding ~\cite{BoehmBerarducci} for arithmetic expressions,
denoted as the type \lstinline{CExp}, is:

\begin{lstlisting}{language=F2J}
type CExp = forall E. (Int -> E) -> (E -> E -> E) -> E
\end{lstlisting}

\noindent However, as done in various solutions to extensibility, it is better to break
down the type of the Church encoding into two parts:

\begin{lstlisting}{language=F2J}
type ExpAlg[E] = {
  lit: Int -> E,
  add: E -> E -> E
};
\end{lstlisting}

\noindent The first part, captured by the type \lstinline{ExpAlg[E]}
is constitutes the so-called algebra of the datatype. For additional
clarity of presentation, records (supported in the implementation of \name)
are used to capture the two components of the algebra. 
The first component abstracts over the type of the
constructor for literal expressions (\lstinline{Int -> E}). The second
component abstracts over the type of addition expressions
(\lstinline{E -> E -> E}).

The second part, which is the actual type of the Church encoding, is:

\begin{lstlisting}{language=F2J}
type Exp = {accept : forall E. ExpAlg[E] -> E};
\end{lstlisting}

\noindent It should be clear that, modulo some refactoring, and the
use of records, the type \lstinline{Exp} and \lstinline{CExp}
are equivalent. 

\paragraph{Data Constructors}
Using \lstinline{Exp} the two data constructors are defined as follows:

\begin{lstlisting}{language=F2J}
let lit (n: Int): Exp = {
  accept = /\E -> \(f: ExpAlg[E]) -> f.lit n
};
let add (e1: Exp) (e2: Exp): Exp = {
  accept = /\E -> \(f: ExpAlg[E]) ->
   f.add (e1.accept[E] f) (e2.accept[E] f)
};
\end{lstlisting}

Note that the notation \lstinline{/\E} in the definition of the
\lstinline{accept} fields is a type abstraction: it
introduces a type variable in the environment. The definition of the
constructors themselves follows the usual Church encodings.

Simple expressions, can be built using the data constructors:

\begin{lstlisting}{language=F2J}
let five : Exp = add (lit 3) (lit 2)
\end{lstlisting}

\paragraph{Operations} Defining operations over expressions requires
implementing \lstinline{ExpAlg[E]}. For example, an interesting
operation over expressions is evaluation. The first step is to define
the evaluation operation is to chose how to instantiate the type
parameter \lstinline{E} in \lstinline{ExpAlg[E]} with a suitable
concrete type for evaluation. One such suitable type is:

\begin{lstlisting}{language=F2J}
 type IEval = {eval: Int};
\end{lstlisting}

\noindent Using \lstinline{IEval}, a record \lstinline{evalAlg}
implementing \lstinline{ExpAlg} is defined as follows:

\begin{lstlisting}{language=F2J}
    let evalAlg: ExpAlg[IEval] = {
      lit = \(x: Int) -> {eval = x},
      add = \(x: IEval) (y: IEval) -> {
        eval = x.eval + y.eval
      }
    };
\end{lstlisting}

In this record, the two operations
\lstinline{lit} and \lstinline{add} return a record with type
\lstinline{IEval}. The definition of \lstinline{eval} for
\lstinline{lit} and \lstinline{add} is straightforward. 


%The type \lstinline$ExpAlg[IEval]$ is the type of object algebras
%supporting evaluation. 
%However, the one interesting point
%of object algebras is that other operations can be supported as
%well.

Using \lstinline{evalAlg}, the expression \lstinline{five} can 
be evaluated as follows:

\begin{lstlisting}{language=F2J}
(five.accept[IEval] evalAlg).eval
\end{lstlisting}

\subsection{Extensibility and Subtyping} Of course, in the Expression
Problem the goal is to achieve extensibility in two dimensions: constructors and operations.
Moreover, in the presence of subtyping it is also interesting to see how the extended datatypes 
relate to the original datatypes. We discuss the two topics next.

\paragraph{New Constructors} Here is the code needed to add a new subtraction constructor:
%Arithmetic expressions with subtyping are defined using the type \lstinline{SubExp}:

\begin{lstlisting}{language=F2J}
type SubExpAlg[E] =
   ExpAlg[E] & {sub: E -> E -> E};

type SubExp = {
   accept: forall A. SubExpAlg[A] -> A
};

let sub (e1: SubExp) (e2: SubExp): SubExp ={
  accept = /\E -> \(f : SubExpAlg[E]) ->
  f.sub (e1.accept[E] f) (e2.accept[E] f)
};
\end{lstlisting}

\noindent Firstly \lstinline{SubExpAlg} defines an extended algebra
that contains the constructors of \lstinline{ExpAlg} plus the new
subtraction constructors. Intersection types are used to do the type 
composition. Secondly, a new type of expressions with subtraction
(\lstinline{SubExp}) is needed. For \lstinline{SubExp} it is important
that the \lstinline{accept} field now takes an algebra of type
\lstinline{SubExpAlg} as argument. This is necessary to define the
constructor for subtraction (\lstinline{sub}), which requires the
algebra to have the field \lstinline{sub}. 


\paragraph{Extending Existing Operations} In order to use evaluation 
with the new type of expressions, it is necessary to also extend
evaluation. Importantly, extension is achieved using the merge operator:

\begin{lstlisting}{language=F2J}
let subEvalAlg = evalAlg ,, {
  sub = \(x: IEval) (y: IEval) -> {
    eval = x.eval - y.eval
  }
};
\end{lstlisting}

\noindent In the code, the merge operator takes \lstinline{evalAlg}
and a new record with the implementation of evaluation for
subtraction, to define the implementation for arithmetic expressions 
with subtraction.

\paragraph{Subtyping} In the presence of subtyping, there are
interesting subtyping relations between datatypes and their
extensions~\cite{oliveira09modular}.  Such subtyping relations are usually not
discussed in theoretical treatments of Church encodings. This is
probably partly due to most work on typed Church encodings being
done in calculi without subtyping.

The interesting aspect about subtyping in typed Church encodings is
that subtyping follows the opposite direction of the extension.  In
other words subtyping is contravariant with respect to the
extension. Such contravariance is explained by the type of the 
\lstinline{accept} field, which is a function where the argument type 
is refined in the extensions. Thus, due to the contravariance of
subtyping on functions, the extension becomes a supertype of the
original datatype. 

In the particular case of expressions \lstinline{Exp} (the original and smaller
datatype) is a subtype of \lstinline{SubExp} (the larger and extended
datatype). Because of this subtyping relation, writting the following
expression is valid in \name:

\begin{lstlisting}{language=F2J}
let three : SubExp = sub five (lit 2)
\end{lstlisting}

\noindent Note the \lstinline{three} is of type \lstinline{SubExp},
but the first argument (\lstinline{five}) to the constructor
\lstinline{sub} is of type \lstinline{Exp}. This can only type-check
if \lstinline{Exp} is indeed a subtype of \lstinline{SubExp}.





\paragraph{New Operations}
The second type of extension is adding a new operation, such as pretty printing.
Similarly to evaluation, the interface of the pretty printing feature
is modeled as:
\begin{comment}
  \begin{lstlisting}{language=F2J}
    type IPrint = {print : String};
  \end{lstlisting}
\end{comment}
\lstinputlisting[linerange=35-35]{../src/ObjectAlgebra.sf} % APPLY:linerange=OA_IPRINT
The implementation of pretty printing for expressions that support literals,
addition, and subtraction is:

\begin{lstlisting}{language=F2J}
let printAlg : SubExpAlg[IPrint] = {
  lit = \(x: Int) -> {print = x.toString()},
  add = \(x: IPrint) (y: IPrint) -> {
    print = x.print ++ " + " ++ y.print
  },
  sub = \(x: IPrint) (y: IPrint) -> {
    print = x.print ++ " - " ++ y.print
  }
};
\end{lstlisting}

\noindent The definition of \lstinline{printAlg} is unremarkable.  
With \lstinline{printAlg} we can pretty print the expression represented
by \lstinline{three}:

\begin{lstlisting}{language=F2J}
(three.accept[IPrint] printAlg).print
\end{lstlisting}

\begin{comment}
The result is \lstinline$"7 - 2"$. Note that the programmer is able to pass \lstinline{lit 2}, which is of type \lstinline{Exp},
to \lstinline{sub}, which expects a \lstinline{SubExp}. The types are compatible
because because \lstinline$Exp$ is a \emph{subtype} of \lstinline$SubExp$. Code
reuse is achieved since we can use the constructors from \lstinline$Exp$ as the
constructor for \lstinline$SubExp$. In Scala, we would have to define two
literal constructors, one for \lstinline$Exp$ and another for
\lstinline$SubExp$.
\end{comment}

\subsection{Composition of Algebras}
The final example shows a non-trivial combinator for algebras that
allows multiple algebras to be combined into one. A version of this
combinator has been encoded in Scala before using intersection types
(which Scala supports) and an encoding of the merge
operator~\cite{oliveira2013feature,rendel14attributes}.
Unfortunatelly, the Scala encoding of the merge operator is quite complex as
it relies on low-level type-unsafe programming features such as
dynamic proxies, reflection or other meta-programming techniques.
In \name there is no need for such hacky encoding, as the
merge operator is nativelly supported. Therefore the combinator for 
composing algebras is implemented much more elegantly. 
The combinator is defined by the \lstinline$combine$ function, which takes two object algebras to create
a combined algebra. It does so by constructing a new algebra
where each field is a function that delegates the input to the two
algebra parameters.

\begin{lstlisting}{language=F2J}
 let combine[A,B * A](f: ExpAlg[A])(g: ExpAlg[B]) : 
   ExpAlg[A&B] = {
     lit = \(x: Int) -> f.lit x ,, g.lit x,
     add = \(x: A & B) (y: A & B) ->
        f.add x y ,, g.add x y
}
\end{lstlisting}

Note how \lstinline{combine} requires all the interesting
features of \name. Parametric polymorphism is needed because
\lstinline{combine} must compose algebras with arbitrary type
parameters. Intersection types are needed because the resulting
algebra will create values with an intersection type composing
the two type parameters of the two input algebras. The merge operator 
is needed to compose the results of each algebra together. Finally, 
a disjointness constraint is needed to ensure that the two input
algebras build values of disjoint types (otherwise ambiguity could
arize).  

With \lstinline{combine} printing and evaluation of expressions with
subtraction is done as follows:

\begin{lstlisting}{language=F2J}
let newAlg : ExpAlg[IEval&IPrint] =
    combine[IEval,IPrint] evalAlg printAlg;
let o = five.accept[IEval&IPrint] newAlg;
o.print ++ " = " ++ o.eval.toString()
\end{lstlisting}

Note that \lstinline$o$ is a value that supports both
evaluation and printing. The final expression uses \lstinline{o}
for doing both printing and evaluation.
