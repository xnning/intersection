\section{Overview}

This section introduces \name and its support for intersection types,
parametric polymorphism and the merge operator. It then discusses
the issue of coherence and shows how the notion of disjoint
intersection types and disjoint quantification is achieves coherence.
Finally we show that \name is powerful enough to express
extensible type-theoretic encodings of datatypes.

Note that this section uses some syntactic sugar, as well as standard
programming language features, to illustrate the various concepts in
\name. Although the minimal core language that we formalize in
Section~\ref{} does not present all such features, our implementation
supports them.

\bruno{Need to type-check the programs!}


\begin{comment}
It then shows that,
with unrestricted intersection types, the system
lacks \emph{coherence}. This motivates the introduction of
disjoint intersection types and extending universal quatification to
disjoint quantification, which is enough to ensure coherence.
\end{comment}

\subsection{Intersection Types and the Merge Operator}
%%\subsection{Intersection Types, Merge and Polymorphism in \name}

Intersection types date back as early as Coppo et
al.'s work~\cite{coppo1981functional}. Since then various researchers have
studied intersection types, and some languages have adopted them in one
form or another.

%However, while intersection types are already used in
%various languages, the lack of a merge operator removes considerable
%expressiveness.

\paragraph{Intersection Types}
The intersection of type $A$ and $B$ (denoted as \lstinline{A & B} in
\name) contains exactly those values
which can be used as either of type $A$ or of type $B$. For instance,
consider the following program in \name:

\begin{lstlisting}
let x : Int & Char = ...;  -- definition ommitted
let idInt (y : Int) : Int = y;
let idChar (y : Char) : Char = y;
(idInt x, idChar x)
\end{lstlisting}

\noindent If a value \lstinline{x} has type \lstinline{Int & Char} then
\lstinline{x} can be used as an integer or as a character. Therefore,
\lstinline{x} can be used as an argument to any function that takes
an integer as an argument, or any
function that take a character as an argument. In the program above
the functions \lstinline{idInt} and \lstinline{idChar} are the
identity functions on integers and characters, respectively. Therefore
passing \lstinline{x} as an argument to either one (or both) of the
functions is valid.

\bruno{text needs to be improved; better connection}
The previous program did not show how to construct values of an
intersection type. Indeed how such values are constructed is a point
of divergence between various proposals for intersections types.

\paragraph{Merge Operator}
\name supports a so-called merge operator. The merge operator allows
two values to be merged in a single intersection type. For example, an
implementation of \lstinline{x} is constructed as follows:

\begin{lstlisting}
let x : Int & Char = 1 ,, 'c';
\end{lstlisting}

\noindent In \name (following the notation of Dunfield~\cite{}), the
merge of two values $v_1$ and $v_2$ is denoted as $v_1 ,, v_2$.

\paragraph{Merge Operator and Pairs}
The merge operator is similar to the introduction construct on pairs.
An analogous implementation of \lstinline{x} with pairs would be:

\begin{lstlisting}
let xPair : (Int, Char) = (1, 'c');
\end{lstlisting}

\noindent The significant difference between intersection types with a
merge operator and pairs is in the elimination construct. With pairs
there are explicit eliminators (\lstinline{fst} and
\lstinline{snd}). These eliminators must be used to extract the
components of the right type. For example, in order to use
\lstinline{idInt} and \lstinline{idChar} with pairs, we would need to
write a program such as:

\begin{lstlisting}
(idInt (fst xPair), idChar (snd xPair))
\end{lstlisting}

\noindent In contrast the elimination of intersection types is done
implicitly, by following a type-directed process. For example,
when a value of type \lstinline{Int} is needed, but an intersection
of type \lstinline{Int & Char} is found, then the compiler uses the
type system to extract the corresponding value.

\subsection{Incoherence}
The merge operator combines two terms, of type $A$ and $B$
respectively, to form a term of type $A \inter B$. For example,
$1 \mergeop `c'$ is of type $\tyint \inter \tychar$. In this case, no
matter $1 \mergeop `c'$ is used as $\tyint$ or $\tychar$, the result
of evaluation is always clear. However, with overlapping types, it is
not straightforward anymore to see the result. For example, what
should be the result of this program, which asks for an integer out of
a merge of two integers:
\[ \app {(\lambda (x : \tyint). x)} {(1 \mergeop 2)} \]
Should the result be $1$ or $2$?

If both results are accepted, we say that the semantics is
\emph{incoherent}: there are multiple possible meanings for the same
valid program. Dunfield's calculus~\cite{} is incoherent and accepts the
program above.

In a real implementation of Dunfield calculus a choice has to be made
on which value to compute. For example, one potential option is to
take either always take the left-most value matching the type in the
merge. Similarly, one could take always take the right-most
value matching the type in the merge. Either way, the meaning
of a program will always depend on an implementation choice.\bruno{why
  is this problematic? say more?}

Moreover, even if it accept either choice as being a good enough
candidate to express the semantics, the approach cannot be easily
extended to systems with parametric polymorphism, as we illustrate
in Section~\ref{}.

\subsection{Restoring Coherence: Disjoint Intersection Types}
Coherence is a desirable property for a semantics. A semantics is said
to be coherent if any \emph{valid program} has exactly one meaning.
One option to restore coherence is to reject programs which may have
multiple meanings.
%Of course, when rejecting programs it is important
%not to be too conservative, and reject too many programs which are
%actually coherent.
Analysing the expression $1 \mergeop 2$, we can see that the reason
for incoherence is that there are multiple, overlapping, integers in the
merge. Generally, if both terms can be assigned some type $C$,
both of them can be chosen as the meaning of the merge,
which leads to multiple meaning of a term.
Thus a natural option is to try to forbid such overlapping
values of the same type in a merge.

This is precisely the approach taken in \name. \name requires that the
two types of in intersection must be \emph{disjoint}.  However,
although disjointness seems a natural restriction to impose on
intersection types, it is not obvious to formalize it. Indeed Dunfield
has mentioned disjointness as an option to restore coherence, but he
left it for future work due to the non-triviality of the approach.

\paragraph{Searching for a Definition of Disjointness}
The first step towards disjoint intersection types is to come up
with a definition of disjointness. A first attempt at such definition would
be to require that, given two types $A$ and $B$, both types are not
subtypes of each other:
\[A * B \equiv A \not<: B \wedge B \not<: A\]
At first sight this seems a reasonable definition and it does prevent
merges such as \lstinline{1 ,, 2}. However some moments of thought are enough to realize that
such definition does not ensure disjointness. For example, consider
the following merge:

\begin{lstlisting}
((1 ,, 'c') ,, (2 ,, True))
\end{lstlisting}

\noindent This merge has two components which are also intersection
types. The first component (\lstinline{(1,,'c')}) has type $\tyint \inter
\tychar$, whereas the second component (\lstinline{(2 ,, True)}) has type
$\tyint \inter \tybool$. Clearly,
\[ \tyint \inter \tychar \not \subtype \tyint \inter \tybool \wedge \tyint \inter \tybool \not \subtype \tyint \inter \tychar \]
Nevertheless the following program still leads to
incoherence:
\[ \app {(\lamty x \tyint x)} {((1 \mergeop 'c') \mergeop (2 \mergeop \code{True}))} \]
as both \lstinline{1} or \lstinline{2} are possible outcomes
of the program. Although this attempt to define disjointness failed,
it did bring us some additional insight: although the types of the two
components of the merge are not subtypes of each other, they share
some types in common.

\paragraph{A Proper Definition of Disjointness} In order for two types
to be trully disjoint, they must not have any subcomponents sharing
the same type. In a system with intersection types this can be ensured
by requiring the two types do not share a common supertype. More
formally:

\bruno{make this a definition!}

\begin{definition}
  Given two types $A$ and $B$, two types are disjoint
  (written $A \disjoint B$) if there is no type $C$ such that both $A$ and $B$ are
  subtypes of $C$:
  \[A \disjoint B \equiv \not\exists C.~A \subtype C \wedge B \subtype C\]
\end{definition}

\noindent This definition of disjointness can prevent the problematic
merge. Since $Int$ is a common supertype of both $Int \& Char$ and
$Int \& Bool$, those two types are not disjoint.

\name's type system only accepts programs that use disjoint
intersection types. As shown in Section~\ref{} this is sufficient to
ensure that the semantics is coherent.

\subsection{Parametric Polymorphism and Disjointness}
The interaction between parametric polymorphism and disjoint
intersection types is non-trivial. The key challange is to have a type
system that still ensures coherence, but at the same time is not too
restrictive in the programs that can be accepted. Dunfield~\cite{} provides a
good illustrative example of the issues that arize when combining
disjoint intersection types and parametric polymorphism:
\[\lambda x. {\bf let}~y = 0 \mergeop x~{\bf in}~x\]
This lambda term, in not a valid \name program, since variables are
not annotated with types. The question is whether we can find
a valid \name program, with type lambdas and type annotations that can
be used to accept the program, or otherwise reject it on the grounds
that disjointness is violated. A first attempt would be:
\[\Lambda A. \lambda (x:A). {\bf let}~y : \tyint \& A = 0 \mergeop x~{\bf in}~x\]
If $A$ is instantiated to $\tybool$ or $\tychar$, for example, then clearly
the merge used in the program ($0 \mergeop x$) respects disjointness. However, if $A$
is instantiated with $Int$ then the merge is problematic as it is not
disjoint.

One option would be to reject the program on the grounds
that $A$ could be instantiated with a type that would allow the
creation of an intersection type which is not disjoint. However this
option would be too conservative and it would prevent many useful
programs using both parametric polymorphism and intersection types.

\begin{comment}
To address the limitations of intersection types in languages like
Scala, \name allows intersecting any two terms at run time using a
\emph{merge} operator (denoted by $ \mergeop $)~\cite{dunfield2014elaborating}.  With the merge
operator it is trivial to implement the \lstinline{merge} function in \name:

\begin{lstlisting}
let merge[A, B * A] (x : A) (y : B) : A & B = x ,, y;
\end{lstlisting}

\noindent In contrast to Scala's term-level \lstinline{with}
construct, the operator \lstinline{,,} allows two arbitrary values \lstinline{x}
and \lstinline{y} to be merged. The resulting type is a \emph{disjoint}
intersection of the types of  \lstinline{x}
and \lstinline{y} (\lstinline{A & B} in this case).



\paragraph{Incoherence and Parametric Polymorphism}
We can define a \code{fst} function that extracts the first item of a merged value:
\[
\code{fst} \ \alpha \ \beta \ (x : \alpha \inter \beta) = \app {(\lam y \alpha y)} x
\]
What should be the result of this program?
\begin{lstlisting}
fst Int Int (1,,2)
\end{lstlisting}

Then we have the following equational reasoning:
\begin{lstlisting}
fst Int Int (1,,2) => (\(y : Int). y) (1,,2)
\end{lstlisting}
If we favour the second item, the program seems to evaluate to $2$. But in
reality, the result is $2$. No matter we favour the first or the second item,
we can always construct a program such that for that program, equational
reasoning is broken.

Therefore, we require that the two types of an intersection must be not
overlapping, or \emph{disjoint}, and add this requirement to the well-formedness of types.

A well-formed type is such that given any query type,
it is always clear which subpart the query is referring to.
In terms of rules, this notion of well-formedness is almost the same as the one in System $F$
except for intersection types we require the two components to be disjoint.

With parametric polymorphism, disjointness is harder to determine due to type variables.
Consider this program:
\[
\blam \alpha {\lam x {\alpha \inter \tyint} x}
\]
$x$ in the body is of type $\alpha \inter \tyint$ and if $\alpha$ and $\tyint$ are
disjoint depends on the instantiation of $\alpha$.


\subsection{Intersection Types in Existing Languages}

What is an intersection type? The intersection of types $A$ and $B$
contains exactly those values which can be used as either of type $A$
or of type $B$.  Just as not all intersection of sets are nonempty,
not all intersections of types are inhabited.  For example, the
intersection of a base type $\tyint$ and a function type
$\tyint \to \tyint$ is not inhabited.\bruno{put this text somewhere?}

Since then various researchers have
studied intersection types, and some languages have adopted in one
form or another. However, while intersection types are already used
in various languages, the lack of a merge operator removes
considerable expressiveness.


A number of OO languages, such as
Java, C\#, Scala, and Ceylon\footnote{\url{http://ceylon-lang.org/}},
already support intersection types to different degrees. Intersection
types are particularly relevant for OOP as they can be used to model
multiple interface inheritance. In Java, for example,

\begin{lstlisting}
interface AwithB extends A, B {}
\end{lstlisting}

\noindent introduces a new interface \lstinline{AwithB} that satisfies the interfaces of
both \lstinline{A} and \lstinline{B}. Arguably such type can be considered as a nominal
intersection type. Scala takes one step further by eliminating the
need of a nominal type. For example, given two concrete traits, it is possible to
use \emph{mixin composition} to create an object that implements both
traits. Such an object has a (structural) intersection type:

\begin{lstlisting}
trait A
trait B

val newAB : A with B = new A with B
\end{lstlisting}

\noindent Scala also allows intersection of type parameters. For example:
\begin{lstlisting}
def merge[A,B] (x: A) (y: B) : A with B = ...
\end{lstlisting}
uses the annonymous intersection of two type parameters \lstinline{A} and
\lstinline{B}. However, in Scala it is not possible to dynamically
compose two objects. For example, the following code:

\begin{lstlisting}
// Invalid Scala code:
def merge[A,B] (x: A) (y: B) : A with B = x with y
\end{lstlisting}

\noindent is rejected by the Scala compiler. The problem is that the
\lstinline{with} construct for Scala expressions can only be used to
mixin traits or classes, and not arbitrary objects. Note that in the
definition \lstinline{newAB} both \lstinline{A} and \lstinline{B} are
\emph{traits}, whereas in the definition of \lstinline{merge} the variables
\lstinline{x} and \lstinline{y} denote \emph{objects}.

This limitation essentially put intersection types in Scala in a second-class
status. Although \lstinline{merge} returns an intersection type, it is
hard to actually build values with such types. In essense an
object-level introduction contruct for intersection types is missing.
As it turns out using low-level type-unsafe programming features such
as dynamic proxies, reflection or other meta-programming techniques,
it is possible to implement such an introduction
construct in Scala~\cite{oliveira2013feature,rendel14attributes}. However, this
is clearly a hack and it would be better to provide proper language
support for such a feature.




\paragraph{Parametric Polymorphism and Intersection Types}
Both universal quantification and intersection types provide a kind of
polymorphism. While the former provides parametric polymorphism, the latter
provides ad-hoc polymorphism. In some systems, parametric polymorphism is
considered the infinite analog of intersection polymorphism. But in our system
we do not consider this relationship. \george{Need to argue that why their
coexistence might be a good thing.} \george{May use the merge example}
\bruno{Some more examples in following subsections?}


To address the limitations of intersection types in languages like
Scala, \name allows intersecting any two terms at run time using a
\emph{merge} operator (denoted by $ \mergeop $)~\cite{dunfield2014elaborating}.  With the merge
operator it is trivial to implement the \lstinline{merge} function in \name:

\begin{lstlisting}
let merge[A, B * A] (x : A) (y : B) : A & B = x ,, y;
\end{lstlisting}

\noindent In contrast to Scala's term-level \lstinline{with}
construct, the operator \lstinline{,,} allows two arbitrary values \lstinline{x}
and \lstinline{y} to be merged. The resulting type is a \emph{disjoint}
intersection of the types of  \lstinline{x}
and \lstinline{y} (\lstinline{A & B} in this case).

\paragraph{Incoherence and Parametric Polymorphism}
We can define a \code{fst} function that extracts the first item of a merged value:
\[
\code{fst} \ \alpha \ \beta \ (x : \alpha \inter \beta) = \app {(\lam y \alpha y)} x
\]
What should be the result of this program?
\begin{lstlisting}
fst Int Int (1,,2)
\end{lstlisting}

Then we have the following equational reasoning:
\begin{lstlisting}
fst Int Int (1,,2) => (\(y : Int). y) (1,,2)
\end{lstlisting}
If we favour the second item, the program seems to evaluate to $2$. But in
reality, the result is $2$. No matter we favour the first or the second item,
we can always construct a program such that for that program, equational
reasoning is broken.

Therefore, we require that the two types of an intersection must be not
overlapping, or \emph{disjoint}, and add this requirement to the well-formedness of types.

A well-formed type is such that given any query type,
it is always clear which subpart the query is referring to.
In terms of rules, this notion of well-formedness is almost the same as the one in System $F$
except for intersection types we require the two components to be disjoint.

With parametric polymorphism, disjointness is harder to determine due to type variables.
Consider this program:
\[
\blam \alpha {\lam x {\alpha \inter \tyint} x}
\]
$x$ in the body is of type $\alpha \inter \tyint$ and if $\alpha$ and $\tyint$ are
disjoint depends on the instantiation of $\alpha$.
\end{comment}

\subsection{Disjoint Quantification}
To allow for more flexibility \name uses an extension to universal
quantification called \emph{disjoint quantification}.  Inspired by
bounded quantification~\cite{}, where a type variable is constrained by a type
bound, disjoint quantification allows a type variable to be
constrained so that it is disjoint with a
given type. With disjoint quantification the previous program, which
is accepted by \name, can be written as:
\[\Lambda A * Int.\lambda (x:A). {\bf let}~y : Int \& A = 0 \mergeop x~{\bf in}~x\]
In this program the type variable $A$ is constrained so that it can be
instantiated with any type disjoint to $Int$. This ensures that the
merge used in the program is disjoint for all valid instantiations of $A$.

Note that there is a nice symmetry between bounded quantification and disjoint quantification.
In systems with bounded quantification,
the usual unconstrained quantifier $\for {\alpha} \ldots$
is a syntactic sugar for $\for {\alpha \subtype \top} \ldots$, and
$\blam \alpha \ldots$ for $\blam {\alpha \subtype \top} \ldots$.
In parellel, in our system with disjoint quantification,
the usual unconstrained quantifier $\for {\alpha} \ldots$
is a syntactic sugar for $\for {\alpha \disjoint \bot} \ldots$, and
$\blam \alpha \ldots$ for $\blam {\alpha \disjoint \top} \ldots$.
The intuition is that since the bottom type is akin to the empty set,
no other type overlaps with it.\george{Format this paragraph better.}

\begin{comment}
With this tool in hand, we can rewrite the program above to:
\[
\blam {\alpha \disjoint \tyint} {\lam x {\alpha \inter \tyint} x}
\]

This program typechecks because while $x$ is of type $\alpha \inter \tyint$,
and $\alpha$ is disjoint with $\tyint$. Similarly, in the new system,
the original program no longer typechecks, thus preventing overlapping types.
\end{comment}

\subsection{Application: Extensible Encodings of Datatypes}
\label{subsec:OAs}

The combination of parametric polymorphism, intersection types and the
merge operator is useful to encode datatypes with subtyping and
support extensibility in \name. Moreover, the combination of
polymorphism and the merge operator is essential to allow the
composition of multiple operations over datatypes. In the following 
we present a step-by-step solution to the Expression Problem in \name, 
and illustrate how to combine multiple operations.

\begin{comment}
Oliveira and Cook~\cite{oliveira2012extensibility} proposed a design pattern that can solve the
Expression Problem in languages like Java. An advantage of the pattern
over previous solutions is that it is relatively lightweight in terms
of type system features. In a latter paper, Oliveira et al.~\cite{oliveira2013feature}
noted some limitations of the original design pattern and proposed
some new techniques that generalized the original pattern, allowing it
to express programs in a Feature-Oriented Programming~\cite{Prehofer97} style.
Key to these techniques was the ability to dynamically compose object
algebras.

Unfortunatelly, dynamic composition of object algebras is
non-trivial. At the type-level it is possible to express the resulting
type of the composition using intersection types. Thus, it is still
possible to solve that part problem nicely in a language like Scala (which
has basic support for intersection types). However, the dynamic
composition itself cannot be easily encoded in Scala. The fundamental
issue is that Scala lacks a \lstinline{merge} operator (see the
discussion in Section~\ref{subsec:interScala}). Although both Oliveira et al.~\cite{oliveira2013feature} and
Rendell et al.~\cite{rendel14attributes} have shown that such a \lstinline{merge} operator can
be encoded in Scala, the encoding fundamentally relies in low-level
programming techniques such as dynamic proxies, reflection or
meta-programming.

Because \name supports a \lstinline{merge} operator natively, dynamic
object algebra composition becomes easy to encode. The remainder of
this section shows how object algebras and object algebra composition
can be encoded in \name. We will illustrate this point
step-by-step by solving the Expression Problem.
%%Prior knowledge of object algebras is not assumed.
\end{comment}
 
% can be cumbersome and
% language support for intersection types would solve that problem.
% Our type system is just a simple extension of System $ F $; yet surprisingly, it
% is able to solve the limitations of using object algebras in languages such as
% Java and Scala.

\paragraph{Church Encoded Arithmetic Expressions}
In the Expression Problem, the idea is to start with a very simple
system modeling arithmetic expressions and evaluation.
The standard Church encoding for arithmetic expressions, 
denoted as the type \lstinline{CExp}, is:

\begin{lstlisting}{language=F2J}
type CExp = forall E. (Int -> E) -> (E -> E -> E) -> E
\end{lstlisting}

\noindent However, for extensibility purposes~\cite{}, it is better to break
down the type of the Church encoding into two parts: 

\begin{lstlisting}{language=F2J}
type ExpAlg[E] = {
  lit: Int -> E, 
  add: E -> E -> E
};
\end{lstlisting}

\noindent The first part, captured by the type \lstinline{ExpAlg[E]}
is constitutes the so-called algebra of the datatype. For additional 
clarity of presentation, we use records to capture the two components
of the algebra. The first component abstracts over the type of the
constructor for literal expressions (\lstinline{Int -> E}). The second 
component abstracts over the type of addition expressions 
(\lstinline{E -> E -> E}). 

The second part, which is the actual type of the Church encoding, is:

\begin{lstlisting}{language=F2J}
type Exp = {accept : forall E. ExpAlg[E] -> E};
\end{lstlisting}

\noindent It should be clear that, modulo some refactoring, and the
use of records, the type \lstinline{Exp} and \lstinline{CExp}
are equivalent.\bruno{more explanation?}

Using \lstinline{Exp} the two data constructors are defined as follows:

\begin{lstlisting}{language=F2J}
let lit (n: Int): Exp = {
  accept = /\E -> \(f: ExpAlg[E]) -> f.lit n
};
let add (e1: Exp) (e2: Exp): Exp = {
  accept = /\E -> \(f: ExpAlg[E]) -> 
   f.add (e1.accept[E] f) (e2.accept[E] f)
};
\end{lstlisting}

Here is an interface that supports evaluation:

\begin{lstlisting}{language=F2J}
 type IEval = {eval: Int};
\end{lstlisting}

Having defined the interfaces, we can implement that object algebra interface
with \lstinline$evalAlg$, which is an object algebra for evaluation.
\begin{comment}
  \begin{lstlisting}{language=F2J}
    let evalAlg: ExpAlg[IEval] = {
      lit = \(x: Int) -> {eval = x},
      add = \(x: IEval) (y: IEval) -> {
        eval = x.eval + y.eval
      }
    };
  \end{lstlisting}
\end{comment}

\lstinputlisting[linerange=15-20]{../src/ObjectAlgebra.sf} % APPLY:linerange=OA_EVALALG
In this example we implement a record, where the two operations
\lstinline{lit} and \lstinline{add} return a record with type \lstinline{IEval}.
The type \lstinline$ExpAlg[IEval]$ is the type of object algebras
supporting evaluation. However, the one interesting point
of object algebras is that other operations can be supported as
well.

\paragraph{Extensibility and Subtyping} In the Expression Problem the goal is to
achieve extensibility in two dimensions: constructors and operations. 

Arithmetic expressions with subtyping are defined using the type \lstinline{SubExp}:

\begin{lstlisting}{language=F2J}
type SubExpAlg[E] = 
   ExpAlg[E] & {sub: E -> E -> E};

type SubExp = {
   accept: forall A. SubExpAlg[A] -> A
};

let sub (e1: SubExp) (e2: SubExp): SubExp ={ 
  accept = /\E -> \(f : SubExpAlg[E]) ->
  f.sub (e1.accept[E] f) (e2.accept[E] f) 
};
\end{lstlisting}


Due to the structural subtyping relation of \name, \lstinline{SubExp}
is a subtype of \lstinline{Exp}.

\begin{lstlisting}{language=F2J}
let subEvalAlg = evalAlg ,, {
  sub = \(x: IEval) (y: IEval) -> { 
    eval = x.eval - y.eval 
  }
};
\end{lstlisting}


\paragraph{Add a pretty printing operation.}
A second extension is adding a new operation, such as pretty printing.
Similar to evaluation, the interface of the pretty printing feature
is modeled as:
\begin{comment}
  \begin{lstlisting}{language=F2J}
    type IPrint = {print : String};
  \end{lstlisting}
\end{comment}
\lstinputlisting[linerange=35-35]{../src/ObjectAlgebra.sf} % APPLY:linerange=OA_IPRINT
The implementation of pretty printing for expressions that support literals,
addition, and subtraction is:
\begin{comment}
  \begin{lstlisting}{language=F2J}
    let printAlg : SubExpAlg[IPrint] = {
      lit = \(x: Int) -> {print = x.toString()},
      add = \(x: IPrint) (y: IPrint) -> {
        print = x.print ++ " + " ++ y.print
      },
      sub = \(x: IPrint) (y: IPrint) -> {
        print = x.print ++ " - " ++ y.print
      }
    };
  \end{lstlisting}
\end{comment}
\lstinputlisting[linerange=39-47]{../src/ObjectAlgebra.sf} % APPLY:linerange=OA_PRINTALG

\paragraph{Usage.} With visitors constructing expressions is quite simple:

\begin{comment}
  \begin{lstlisting}{language=F2J}
    e2 = sub (lit 7) (lit 2)
  \end{lstlisting}
\end{comment}
\lstinputlisting[linerange=49-50]{../src/Visitor.sf} % APPLY:linerange=V_USAGE
The result is \lstinline$"7 - 2"$. Note that the programmer is able to pass \lstinline{lit 2}, which is of type \lstinline{Exp},
to \lstinline{sub}, which expects a \lstinline{SubExp}. The types are compatible
because because \lstinline$Exp$ is a \emph{subtype} of \lstinline$SubExp$. Code
reuse is achieved since we can use the constructors from \lstinline$Exp$ as the
constructor for \lstinline$SubExp$. In Scala, we would have to define two
literal constructors, one for \lstinline$Exp$ and another for
\lstinline$SubExp$. 

\paragraph{Dynamic object algebra composition.}
To obtain an expression that supports both evaluation and pretty
printing, a mechanism to combine the evaluation and printing
algebras is needed. \name allows such composition: the \lstinline$combine$
function, which takes two object algebras to create a combined algebra. It
does so by constructing a new object algebra where each field is a
function that delegates the input to the two algebra parameters.
\begin{comment}
  \begin{lstlisting}{language=F2J}
    let combine[A,B](f: ExpAlg[A])(g: ExpAlg[B]) :
    ExpAlg[A&B] = {
      lit = \(x: Int) -> f.lit x ,, g.lit x,
      add = \(x: A & B) (y: A & B) ->
      f.add x y ,, g.add x y
    }
  \end{lstlisting}
\end{comment}
\lstinputlisting[linerange=58-63]{../src/ObjectAlgebra.sf} % APPLY:linerange=OA_COMBINE

\begin{comment}
  \begin{lstlisting}{language=F2J}
    let newAlg =
    combine[IEval,IPrint] subEvalAlg printAlg;
    let o = e1[IEval&IPrint] newAlg;
    o.print ++ " = " ++ o.eval.toString()
  \end{lstlisting}
\end{comment}

\lstinputlisting[linerange=67-69]{../src/ObjectAlgebra.sf} % APPLY:linerange=OA_USAGE

Note that \lstinline$o$ is a single object that supports both
evaluation and printing, as the output of the program is
\begin{lstlisting}
> 7 + 2 = 9
\end{lstlisting}

In contrast to the Scala solutions available in the
literature, \name is able to express object algebra
composition very directly by using the merge operator.
