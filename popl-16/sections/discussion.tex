\section{Discussion}
\label{sec:discussion}

\subsection{Union Types}

% \bruno{Digressions are bad; they break the flow. I suggest that the
%   point about union types and the point about systems with a top type
%   is moved to a discussion section towards the end of the paper.}

Given this definiton, now may be the right time to take a short digression to
consider union types. If a type system ever contains union types (the
counterpart of intersection types), with the following standard subtyping rules,
\begin{mathpar}
  \inferrule* [right=Union\_1]
    { }
    {A \subtype A \union B}

  \inferrule* [right=Union\_2]
    { }
    {B \subtype A \union B}
\end{mathpar}
then no two types $A$ and $B$ can ever be disjoint, since there always exists
the type $A \union B$, which is their common supertype. This serve as the
motivation that our system does not permit union types.
\bruno{I wouldn't say this is a motivation: it sounds like we caould
  not support union types, when I think this is not true. For example
we could say something like: there does not exist an \emph{atomic} C ...}

\subsection{Normalising Types}

Since the order of the two types in a binary intersection does not matter, we
may normalise them to avoid unnecessary coercions.

We implemented the core functionalities of the \name as part of a JVM-based
compiler. The implementation supports record update instead of restriction as a
primitive; however the former is formalized with the same underlying idea of
elaborating records. Based on the type system of \name, we built an ML-like
source language compiler that offers interoperability with Java (such as object
creation and method calls). The source language is loosely based on the more
general System $F_{\omega}$ and supports a
number of other features, including multi-field records, mutually recursive
\code{let} bindings, type aliases, algebraic data types, pattern matching, and
first-class modules that are encoded with \code{letrec} and records.

Relevant to this paper are the three phases in the compiler, which
collectively turn source programs into System $F$:

\begin{enumerate}
\item A \emph{typechecking} phase that checks the usage of \name features and
  other source language features against an abstract syntax tree that follows
  the source syntax.

\item A \emph{desugaring} phase that translates well-typed source terms into
  \name terms. Source-level features such as multi-field records, type aliases
  are removed at this phase. The resulting program is just an \name term
  extended with some other constructs necessary for code generation.

\item A \emph{translation} phase that turns well-typed \name terms into System
  $F$ ones.
\end{enumerate}

Phase 3 is what we have formalized in this paper.

\paragraph{Removing identity functions.} Our translation inserts identity
functions whenever subtyping or record operation occurs, which could mean
notable run-time overhead. But in practice this is not an issue. In the current
implementation, we introduced a partial evaluator with three simple rewriting
rules to eliminate the redundant identity functions as another compiler phase
after the translation. In another version of our implementation, partial
evaluation is weaved into the process of translation so that the unwanted
identity functions are not introduced during the translation.
