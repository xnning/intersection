\section{Related Work}
\label{sec:related-work}

%*******************************************************************************
\paragraph{Coherence}
%*******************************************************************************

Reynolds invented Forsythe~\cite{reynolds1997design} in the 1980s. Our
merge operator is analogous to his operator $p_1, p_2 $. Forsythe has
a coherent semantics. The result was proved formally by
Reynolds~\cite{reynolds1991coherence} in a lambda calculus with
intersection types and a merge operator. However there are two key
differences to our work. Firstly the way coherence is ensured is
rather ad-hoc. He has four different typing rules for the merge
operator, each accounting for various possibilities of what the types
of the first and second components are. In some cases the meaning of
the second component takes precedence (that is, is biased) over the
first component. The set of rules is restrictive and it forbids, for
instance, the merge of two functions (even when they a provably
disjoint). In contrast, disjointness in \name has a well-defined
specification and it is quite flexible. Secondly, Reynolds calculus
does not support universal quantification. It is unclear to us whether
his set of rules would still ensure disjointness in the presence of
universal quantification. Since some biased choice is allowed in
Reynold's calculus the issues illustrated in Section~\ref{subsec:polymorphism} could be a problem.

Pierce~\cite{pierce1991programming2} made a comprehensive review
of coherence, especially on Curien and Ghelli~\cite{curienl1990coherence} and
Reynolds' methods of proving coherence; but he was not able to prove coherence
for his $F_\wedge$ calculus. He introduced a primitive $\code{glue}$ function as
a language extension which corresponds to our merge operator. However, in his
system users can ``glue'' two arbitrary values, which can lead to incoherence.

Our work is largely inspired by Dunfield~\cite{dunfield2014elaborating}. He
described a similar approach to ours: compiling a system with intersection types
and a merge operator into ordinary $ \lambda $-calculus terms with pairs. One
major difference is that our system does not include unions. However, as
acknowledged by Dunfield, his calculus lacks of coherence. He discusses the
issue of coherence throughout his paper, mentioning biased choice as an option
(albeit a rather unsatisfying one). He also mentioned that the notion of
disjoint intersection could be a good way to address the problem, but he did not
pursue this option in his work. In contrast to his work, we developed a type
system with disjoint intersection types and proposed disjoint quantification to
guarantee coherence in our calculus.

% \url{http://homepages.inf.ed.ac.uk/gdp/publications/Sub_Par.pdf}

% \cite{plotkin1994subtyping}

% Also discussed intersection types!~\cite{malayeri2008integrating}.

% Pierce Ph.D thesis: F<: + /|
%        technical report: F + /|, closer to ours

% \cite{barbanera1995intersection}
%
% \paragraph{Intersection types with polymorphism.}
% Our type system combines intersection types and parametric polymorphism. Closest
% to us is Pierce's work~\cite{pierce1991programming1} on a prototype
% compiler for a language with both intersection types, union types, and
% parametric polymorphism. Similarly to \name in his system universal
% quantifiers do not support bounded quantification. However Pierce did not try to prove any
% meta-theoretical results and his calculus does not have a merge
% operator.  Pierce also studied a system where both intersection
% types and bounded polymorphism are present in his Ph.D.
% dissertation~\cite{pierce1991programming2} and a 1997
% report~\cite{pierce1997intersection}.

Going in the direction of higher
kinds, Compagnoni and Pierce~\cite{compagnoni1996higher} added
intersection types to System $ F_{\omega} $ and used the new calculus,
$ F^{\omega}_{\wedge} $, to model multiple inheritance. In their
system, types include the construct of intersection of types of the
same kind $ K $. Davies and Pfenning
\cite{davies2000intersection} studied the interactions between
intersection types and effects in call-by-value languages. And they
proposed a ``value restriction'' for intersection types, similar to
value restriction on parametric polymorphism. Although they proposed a system with
parametric polymorphism, their subtyping rules are significantly different from ours,
since they consider parametric polymorphism
as the ``infinit analog'' of intersection polymorphism.

Recently,
Castagna et al.~\cite{Castagna:2014} studied an very expressive calculus that
has polymorphism and set-theoretic type connectives (such as intersections,
unions, and negations). As a result, in their calculus one is also able to
express a type variable that can be instantiated to any type other than
$\code{Int}$ as $\alpha \setminus \code{Int}$, which is syntactic sugar for
$\alpha \wedge \neg \code{Int}$. As a comparison, such a type will need a
disjoint quantifier, like $\fordis \alpha {\code{Int}} \alpha$, in our system.
Unfortunately their calculus does not include a merge operator like ours.

There have been attempts to provide a foundational calculus
for Scala that incorporates intersection
types~\cite{amin2014foundations,amin2012dependent}.
Although the minimal Scala-like calculus does not natively support
parametric polymorphism, it is possible to encode parametric
polymorphism with abstract type members. Thus it can be argued that
this calculus also supports intersection types and parametric
polymorphism. However, the type-soundness of a minimal Scala-like
calculus with intersection types and parametric polymorphism is not
yet proven. Recently, some form of intersection
types has been adopted in object-oriented languages such as Scala,
Ceylon, and Grace. Generally speaking,
the most significant difference to \name is that in all previous systems
there is no explicit introduction construct like our merge operator. As shown in
Section~\ref{subsec:OAs}, this feature is pivotal in supporting modularity
and extensibility because it allows dynamic composition of values.

\begin{comment}
only allow intersections of concrete types (classes),
whereas our language allows intersections of type variables, such as
\texttt{A \& B}. Without that vehicle, we would not be able to define
the generic \texttt{merge} function (below) for all interpretations of
a given algebra, and would incur boilerplate code:

\begin{lstlisting}
let merge [A, B] (f: ExpAlg A) (g: ExpAlg B) = {
  lit (x : Int) = f.lit x ,, g.lit x,
  add (x : A & B) (y : A & B) =
    f.add x y ,, g.add x y
}
\end{lstlisting}
\end{comment}

%*******************************************************************************
\paragraph{Other type systems with intersection types.}
%*******************************************************************************

% Although similar in spirit,
% our elaboration typing is simpler: we require subtyping in the case of
% applications, thus avoiding the subsumption rule. Besides, our treatment
% combines the merge rules ($ k $ ranges over $ \{1, 2\} $)
% \inferrule
% {\Gamma \turns e_k : A}
% {\Gamma \turns e_1 \mergeop e_2 : A}
% and the standard intersection-introduction rule
% \inferrule
% {\Gamma \turns e : A_1 \andalso \Gamma \turns e : A_2}
% {\Gamma \turns e : A_1 \inter A_2}
% into one rule:
% \inferrule [Merge]
% {\Gamma \turns e_1 : A_1 \andalso \Gamma \turns e_2 : A_2}
% {\Gamma \turns e_1 \mergeop e_2 : A_1 \inter A_2}
%Castagna, and Dunfield describe
%elaborating multi-fields records into merge of single-field records.
% Reynolds and Castagna do not consider elaboration and Dunfield do not
% formalize elaborating records.
% Both Pierce and Dunfield's system include a subsumption rule, which states that
% if an term has been inferred of type $ A $, then it is also of any
% supertype of $ A $. Our system does not have this rule.
Refinement
intersection~\cite{dunfield2007refined,davies2005practical,freeman1991refinement}
is the more conservative approach of adopting intersection types. It increases
only the expressiveness of types but not terms. But without a term-level
construct like ``merge'', it is not possible to encode various language
features. As an alternative to syntactic subtyping described in this paper,
Frisch et al.~\cite{frisch2008semantic} studied semantic subtyping. Semantic
subtyping seems to have important advantages over syntactic subtyping. One
worthy avenue for future work is to study languages with intersection types
and merge operator in a semantic subtyping setting.

%*******************************************************************************
\paragraph{Extensibility.}
%*******************************************************************************
One of our motivations to study systems
with intersections types is to better understand the
type system requirements needed to address extensibility problems.
A well-known problem in programming languages is the Expression
Problem~\cite{wadler1998expression}. In recent years there have been
various solutions to the Expression Problem in the literature. Mostly
the solutions are presented in a specific language, using the language
constructs of that language. For example, in Haskell, type classes~\cite{WadlerB89}
can be used to implement type-theoretic encodings of
datatypes~\cite{Hinze:2006}. It has been shown~\cite{finally-tagless}
that, when encodings of datatypes are modeled with type classes,
the subclassing mechanism of type classes can be used to achieve
extensibility and reuse of operations. Using such techniques provides
a solution to the Expression Problem. Similarly, in OO languages with
generics, it is possible to use generic interfaces and classes to
implement type-theoretic encodings of datatypes. Conventional
subtyping allows the interfaces and classes to be extended, which can
also be used to provide extensibility and reuse of operations. Using
such techniques, it is also possible to solve the Expression Problem
in OO languages~\cite{oliveira09modular,oliveira2012extensibility}.
It is even possible to solve the Expression Problem in theorem provers
like Coq, by exploiting Coq's type class mechanism~\cite{DelawareOS13}.
Nevertheless, although there is a clear connection between all those
techniques and type-theoretic encodings of datatypes, as far as we
know, no one has studied the expression problem from a more
type-theoretic point of view.

% As shown in Section~\ref{subsec:OAs}, a system
% with intersection types, parametric polymorphism, the merge operator
% and disjoint quantification can be used to explain type-theoretic
% encodings with subtyping and extensibility.

% Intersection types have been shown to be useful in designing languages that
% support modularity.~\cite{nystrom2006j}

% \paragraph{Extensible records.}

%\george{Record field deletion is also possible.}

% http://elm-lang.org/learn/Records.elm

% Encoding records using intersection types appeared in
% Reynolds~\cite{reynolds1997design} and Castagna et
% al.~\cite{castagna1995calculus}. Although Dunfield also discussed this idea in
% his paper \cite{dunfield2014elaborating}, he only provided an implementation but
% not a formalization. Very similar to our treatment of elaborating records is
% Cardelli's work~\cite{cardelli1992extensible} on translating a calculus, named
% $ F_{\subtype \rho}$, with extensible records to a simpler calculus that without
% records primitives (in which case is $ F_{\subtype} $). But he did not consider
% encoding multi-field records as intersections; hence his translation is more
% heavyweight. Crary~\cite{crary1998simple} used intersection types and
% existential types to address the problem that arises when interpreting method
% dispatch as self-application. But in his paper, intersection types are not used
% to encode multi-field records.

% Wand~\cite{wand1987complete} started the work on extensible records and proposed
% row types~\cite{wand1989type} for records. Cardelli and
% Mitchell~\cite{cardelli1990operations} defined three primitive operations on
% records that are similar to ours: \emph{selection}, \emph{restriction}, and
% \emph{extension}. The merge operator in \name plays the same role as extension.
% Following Cardelli and Mitchell's approach,
% of restriction and extension. Both Leijen's systems~\cite{leijen2004first,leijen2005extensible}
% and ours allow records that contain
% duplicate labels. Leijen's system is more sophisticated. For example, it supports
% passing record labels as arguments to functions. He also showed an encoding of
% intersection types using first-class labels.

% Chlipala's
% \texttt{Ur}~\cite{chlipala2010ur} explains record as type level
% constructs.\bruno{What is the point of citing Chlipala's paper?}

% Our system can be adapted to simulate systems that support extensible
% records but not intersection of ordinary types like \texttt{Int} and
% \texttt{Float} by allowing only intersection of record types.
%
% $ \turnsrec A $ states that $ A $ is a record type, or the intersection of
% record types, and so forth.
%
% \inferrule [RecBase] {} {\turnsrec \recordType l A}
%
% \inferrule [RecStep]
% {\turnsrec A_1 \andalso \turnsrec A_2}
% {\turnsrec A_1 \inter A_2}
%
% \inferrule [Merge']
% {\Gamma \turns e_1 : A_1 \yields {E_1} \andalso \turnsrec A_1 \\
%  \Gamma \turns e_2 : A_2 \yields {E_2} \andalso \turnsrec A_2}
% {\Gamma \turns e_1 \mergeop e_2 : A_1 \inter A_2 \yields {\pair {E_1} {E_2}}}
%
% R{\'e}my~\cite{remy1989type}

%*******************************************************************************
\paragraph{Trait calculi.}
%*******************************************************************************
Fisher and Reppy~\cite{fisher2004typed} provided a dedicated statically typed
calculus for modeling traits. \name is not dedicated to traits; but rather, it
supports a source language that models traits. Compared to Fisher and Reppy's
calculus, \name is more lightweight. For example, self reference is not in the
language of \name. One reason for the difference is that Fisher and Reppy's
calculus supports \emph{classes} in addition to traits, and considers the
interaction between them, whereas our object oriented source language is
\emph{prototype}-based---the mechanism for code reuse is purely trait.
