\section{Overview} \label{sec:overview}

This section introduces \name and its support for intersection types,
parametric polymorphism and the merge operator. 
It then discusses the issue of coherence and shows how the notion of disjoint
intersection types and disjoint quantification achieves a coherent semantics.
This section uses some syntactic sugar, as well as standard
programming language features, to illustrate the various concepts in \name. 
Although the minimal core language that we formalize in
Section~\ref{sec:fi} does not present all such features, such
syntactic sugar is trivial to add.

\subsection{Intersection Types and the Merge Operator}

\paragraph{Intersection types.}
The intersection of type $A$ and $B$ (denoted as \lstinline{A & B} in
\name) contains exactly those values
which can be used as both values of type $A$ and of type $B$. 
For instance, consider the following program in \name:

\begin{lstlisting}
let x : Int & Bool = (*$ \ldots $*) in -- definition omitted
let succ (y : Int) : Int = y+1 in
let not (y : Bool) : Bool = if y then False else True in (succ x, not x)
\end{lstlisting}

\noindent If a value \lstinline{x} has type \lstinline{Int & Bool} then
\lstinline{x} can be used anywhere where either a value of type \lstinline{Int} or  
a value of type \lstinline{Bool} is expected. 
This means that, in the program above
the functions \lstinline{succ} and \lstinline{not} -- simple functions 
on integers and booleans, respectively -- both accept \lstinline{x} as an argument. 

\paragraph{Merge operator.}
The previous program deliberately ommitted the introduction of values of an
intersection type. 
There are many variants of intersection types in the literature. 
Our work follows a particular
formulation, where
intersection types are introduced by a \emph{merge operator}~\cite{reynolds1997design,reynolds1991coherence,Castagna92calculus,dunfield2014elaborating,oliveira16disjoint}. 
As Dunfield~\cite{dunfield2014elaborating} has argued a merge operator adds considerable
expressiveness to a calculus. 
The merge operator allows two values to be merged in a single intersection type. 
For example, an implementation of \lstinline{x} in \name is \lstinline{1,,True}.
Following Dunfield's notation the merge of $v_1$ and $v_2$ is denoted as $v_1 ,, v_2$.

\begin{comment}
\paragraph{Merge vs Pairs}
The significant difference between intersection types with a
merge operator and regular pairs is in the elimination construct. 
With pairs there are explicit eliminators (\lstinline{fst} and
\lstinline{snd}), and these eliminators must be used to extract the
components of the right type.
With intersection types and a merge operator, elminators are implicit in the language,
meaning no uses of projection functions are necessary.
\end{comment}

%\paragraph{Merge operator and pairs.}
%The merge operator is similar to the introduction construct on pairs.
%An analogous implementation of \lstinline{x} with pairs would be:

%\begin{lstlisting}
%let xPair : (Int, Char) = (1, 'c') in (*$ \ldots $*)
%\end{lstlisting}

% For example, in order to use
%\lstinline{idInt} and \lstinline{idChar} with pairs, we would need to
%write a program such as:

%\begin{lstlisting}
%(idInt (fst xPair), idChar (snd xPair))
%\end{lstlisting}

%\noindent In contrast the elimination of intersection types is done
%implicitly, by following a type-directed process. For example,
%when a value of type \lstinline{Int} is needed, but an intersection
%of type \lstinline{Int & Char} is found, the compiler uses the
%type system to extract the corresponding value.

\subsection{Coherence and Disjointness}
\label{subsec:coherence}
Coherence is a desirable property for a semantics. 
A semantics is coherent if any \emph{valid program} has exactly one
meaning~\cite{reynolds1991coherence} (that is, the semantics is not ambiguous).
Unfortunately the implicit nature of elimination for intersection
types built with a merge operator can lead to incoherence.
This is due to intersections with overlapping types, as in
$\tyint \inter \tyint$.
The result of the program (\lstinline$(1,,2) : Int$)
can be either \lstinline$1$ or \lstinline$2$, depending on the implementation 
of the language.

\paragraph{Disjoint intersection types}
One option to restore coherence is to reject programs which may have
multiple meanings.  The \oldname calculus~\cite{oliveira16disjoint} --
a simply-typed calculus with intersection types and a merge operator
-- solves this problem by using the concept of disjoint intersections.
The incoherence problem with the expression $1 \mergeop 2$
happens because there are two overlapping integers in the merge. 
Generally speaking, if both terms can be assigned some type $C$
then both of them can be chosen as the meaning of the merge,
which in its turn leads to multiple meanings of a term.
Thus a natural option is to forbid such overlapping
values of the same type in a merge. In \oldname 
intersections such as \lstinline{Int&Int} are forbidden, since 
the types in the intersection overlap (i.e. they are not disjoint). However an intersection 
such as \lstinline{Char&Int} is ok because the set of characters 
and integers are disjoint to each other. 

\begin{comment}
This is precisely the approach taken in \oldname: a merge can only be composed of
two values as long as their types are \emph{disjoint}.  
Disjointness is a binary relation between two types, defined for any types which
do not contain any overlapping types. For example \lstinline{Int&Char}
is disjoint to \lstinline{Bool} because  but \lstinline{
\end{comment}

%It can be specified as: given any two types, they are disjoint if there does not 
%exist any common super-type.

\begin{comment}
More formally, the notion of disjointness can be specified as follows:
\bruno{I think we should avoid presenting the specification, since we
  do not have one for this paper. We can refer to this in the related
  work.}

\begin{definition}[Disjointness]
  Given two types $A$ and $B$, two types are disjoint
  (written $A \disjoint B$) if there is no type $C$ such that both $A$ and $B$ are
  subtypes of $C$:
  \[A \disjoint B \equiv \not\exists C.~A \subtype C \wedge B \subtype C\]
\end{definition}

With this concept of disjointness in mind, it is easy to verify that the previous example 
will no longer be accepted since \lstinline$((1,,2) : Int)$ is no longer well-typed!
The merge operator requires two types to be disjoint in order to type-check it into
an intersection.
In the example \lstinline$(1,,2)$ is rejected by the compiler, since \lstinline$Int$ is not
disjoint with \lstinline$Int$.
In other words, there exists a super-type of both \lstinline$Int$ and \lstinline$Int$, 
namely \lstinline$Int$ itself.
This result can be generalized and \oldname has shown that it can lead to a coherent calculus. 
Although this is a promising result, the question remains: is it possible to incorporate 
parametric polymorphism in such calculus, while retaining coherence?
\end{comment}

%\oldname not only provided a specification for disjointness but also an algorithmic version
%of it, and proved that both versions are equivalent.
%This turned disjointness as a concept which is both easy to understand and easy to implement. 

\begin{comment}
\subsection{Top-like types}\bruno{You are spending too much time to
  get to the point. When writting a paper you want to get to the point
  (what's the problem) 
as fast as possible. So you should have enough background to understand
the paper, but keep that background minimal. Look at the ICFP paper: 
we got to Section 2.2 (the problem) in less than a column.
I think we don't need to
cover top-like types here. They are not essential. }
The \oldname calculus also showed how to extend the type system with a type $\top$, the supertype 
of all types.
Since introducing $\top$ leads to a useless disjointness specification (i.e. no type is disjoint to
any other type) and introduces some ambiguity because $\top \subtype \top \inter \top$ and
$\top \inter \top \subtype \top$.
Therefore, the specification was changed to the following:

\begin{definition}[$\top$-disjointness]
  Two types $A$ and $B$ are disjoint
  (written $A \disjoint B$) if the following two conditions are satisfied:
\begin{enumerate}
  \item $(\text{not}~\toplike{A})~\text{and}~(\text{not}~\toplike{B}) $
  \item $\forall C.~\text{if}~ A \subtype C~\text{and}~B \subtype C~\text{then}~\toplike{C}$
\end{enumerate}
\end{definition}
The unary relation $\toplike{\cdot}$ represents the so-called top-like types, which are types that resemble 
$\top$.
This set of types includes $\top$ itself, intersections composed of other 
top-like types (i.e. $\top \inter \top$), and pre-top-types, which are functions that have
$\top$ as their co-domain (i.e. $\tyint \to \tychar \to \top$).
\end{comment}

\subsection{Parametric Polymorphism}
Unfortunately, combining parametric polymorphism with disjoint
intersection types is non-trivial. Consider the following program
(uppercase Latin letters to denote type variables):

\begin{lstlisting}
let merge3 A (x : A) : A & Int = x,,3 in
\end{lstlisting}

\noindent The \lstinline{merge3} function takes an argument
\lstinline{x} of some type (\lstinline{A}) and merges \lstinline{x}
with \lstinline{3}. Thus the return type of the program is
\lstinline{A & Int}. \lstinline{merge3} is unproblematic for many
possible instantiations of \lstinline{A}.  However, if
\lstinline{merge3} instantiates \lstinline{A} with a type that
overlaps (i.e. is not disjoint) with \lstinline{Int}, then incoherence may happen.
For example:

\begin{lstlisting}
merge3 Int 2
\end{lstlisting}

\noindent can evaluate to both 2 or 3. 

\paragraph{Forbidding type variables in intersections} 
A naive way to ensure that only programs with disjoint types are accepted is 
simply to forbid type variables in intersections. That is, an
intersection type such as \lstinline{Char&Int} would be accepted, 
but an intersection such as \lstinline{A&Int} (where \lstinline{A} is
some type variable) would be rejected. The reasoning behind this
design is that type variables can be instantiated to any types,
including those already in the intersection. Thus forbidding type
variables in the intersection will prevent invalid intersections
arizing from instantiations with overlapping types.

Such design does guarantee coherence and would prevent
\lstinline{merge3} from type-checking. Unfortunatelly the big drawback
is that the design is too conservative and many other (useful) programs would be 
rejected. In particular, the \lstinline{extend} function from Section~\ref{sec:intro}
would also be rejected. 

\paragraph{Other approaches}
Another option to mitigate the issues of incoherence, without using
disjoint intersection types is to allow for a biased choice: that is
multiple values of the same type may exist in an intersection, but an
implementation gives preference to one of them. The encodings of merge 
operators in TypeScript and Scala~\cite{oliveira2013feature} use such an approach.
A first problem with this approach, which has already been pointed out by
Dunfield~\cite{dunfield2014elaborating}, is that the choice of the corresponding value is
tied up to a particular choice in the implementation. In other words
incoherence still exists at the semantic level, but the implementation makes it predictable 
which overlapping value will be chosen. From the
theoretical point-of-view it would be much better to have a clear,
coherent semantics, which is independent from concrete implementations.
Another problem is that the interaction between 
biased choice and polymorphism can lead to counter-intuitive programs, since
instantiation of type-variables affects the type-directed lookup of a
value in an intersection.

\begin{comment}
\paragraph{Biased choice} An option to mitigate the issues of
incoherence, without using disjoint intersection types
is to allow for a biased
choice: that is multiple values of the same type may exist in an
intersection, but an implementation gives preference to one of them.

A first problem with this approach, which has already been pointed out by
Dunfield~\cite{}, is that the choice of the corresponding value is
tied up to a particular choice in the implementation. From the
theoretical point-of-view it would be much better to have a clear, and
unambiguous semantics. 

However, things get even worse in the  presence of polymorphism.
Consider the attempt to write the following polymorphic function in such system: 
\begin{lstlisting}
let fst A B (x: A & B) : A = x in (*$ \ldots $*)
\end{lstlisting}
The \code{fst} function is supposed to extract a value of type
\lstinline{A} from the merge value $x$ (of type \lstinline{A&B}). 
This function can be problematic when
\lstinline{A} and \lstinline{B} are instantiated to non-disjoint
types. 

\paragraph{Biased choice breaks equational reasoning.} 
At first sight, one option
to workaround the incoherence issue would be to bias the type-based merge lookup
to the left or to the right. %(as discussed in Section~\ref{subsec:incoherence}). 
However, biased choice is
very problematic when parametric polymorphism is present in the language.
To see the issue, suppose we chose to always pick the
rightmost value in a merge when multiple values of same type exist.
Intuitively, it would appear that the result of the use of
\lstinline{fst} above is $2$. 
Indeed simple equational reasoning seems to validate such result:
\begin{lstlisting}
   fst Int Int (1,,2)
(*$ \rightsquigarrow $*) ((fun z (*$ \to $*) z) : Int (*$ \to $*) Int) (1,,2) -- (* \textnormal{By the definition of \code{fst}} *)
(*$ \rightsquigarrow $*) ((fun z (*$ \to $*) z) : Int (*$ \to $*) Int) 2      -- (* \textnormal{Right-biased coercion} *)
(*$ \rightsquigarrow $*) 2                                  -- (* \textnormal{By $\beta$-reduction} *)
\end{lstlisting}

However (assuming a straightforward implementation of right-biased
choice) the result of the program would be 1! The reason for this has
todo with \emph{when} the type-based lookup on the merge happens. In
the case of \lstinline{fst}, lookup is triggered by a coercion
function inserted in the definition of \lstinline{fst} at
compile-time.
In the definition of \lstinline$fst$ all it is known is that a
value of type $A$ should be returned from a merge with an intersection
type $A\&B$.  
Clearly the only type-safe choice to coerce the value of type $A\&B$ into $A$ is to
take the left component of the merge. 
This works perfectly for merges
such as \lstinline$(1,,'c')$, where the types of the first and second components
of the merge are disjoint. 
For the merge \lstinline$(1,,'c')$, if a integer lookup
is needed, then \lstinline$1$ is the rightmost integer, which is consistent with the
biased choice. 
Unfortunately, when given the merge \lstinline$(1,,2)$ the
left-component \lstinline$1$ is also picked up, even though in this case \lstinline$2$
is the rightmost integer in the merge. 

The subtle interaction of polymorphism and type-based lookup
means that equational reasoning is broken.
In the equational reasoning steps above, doing apparently correct
substitutions lead us to a wrong result. 
This is a major problem for biased choice and a reason to dismiss it as a possible implementation
choice for \name.

\paragraph{A more conservative attempt.}
Another attempt at restoring coherence can be to forbid type variables inside
intersections (i.e. type variables are not disjoint to any type).
This conservative approach would solve the problem of coherence, but it would also greatly 
restrict the expressiveness of the resulting language.
For example, the function $fst$ defined above, would no longer be accepted by the system.
In fact, parametric polymorphism and intersection types could only be mixed in a very limited manner -
as long as variables do not reside under intersections - and this is arguably a useful improvement
in respect to other standard type systems, such as System $F$.
\end{comment}


\begin{comment}
\subsection{Disjoint Polymorphism}
A more liberal solution,which enables the combination of type
variables and intersection types, is disjoint polymorphism.
Disjoint polymorphism assign constraints to each type variable, which
allows delaying the check for disjointness until type application/instantiation. 
\end{comment}

\subsection{Disjoint Polymorphism}\label{subsec:disjoint-quantification}
To avoid being overly conservative, while still retaining coherence in the
presence of parametric polymorphism and intersection types, \name uses
\emph{disjoint polymorphism}.
Inspired by bounded quantification~\cite{Cardelli:1994},
where a type variable is constrained by a type bound, disjoint polymorphism 
allows type variables to be constrained so that they are disjoint to some
given types. 

With disjoint quantification a variant of the program $merge3$, which
is accepted by \name, is written as:

\begin{lstlisting}
let merge3 ((*$ \highlight {A *~Int} $*)) (x : A) : A & Int = x,,3 in
\end{lstlisting}

\noindent In this variant the type \lstinline{A} can be instantiated
to any types disjoint to \lstinline{Int}. Such restriction is
expressed by the notation \lstinline{A * Int}, where the left-side of 
\lstinline{*} denotes the type variable being declared (\lstinline{A}), and the
right-side denotes the disjointness constraint (\lstinline{Int}).
For example, 

\begin{lstlisting}
merge3 Bool True
\end{lstlisting}

\noindent is accepted. However, instantiating \lstinline{A} with
\lstinline{Int} fails to type-check. 

\paragraph{Multiple constraints} Disjoint quantification allows for
multiple constraints. For example, in the following variant of the
\lstinline{merge3} there is an additional boolean in the merge:

\begin{lstlisting}
let merge3b ((*$ \highlight {A *~Int \&~Bool} $*)) (x : A) : A & Int & Bool = x,,3,,True in
\end{lstlisting}

\noindent In this case the type variable \lstinline{A} needs to be
disjoint to both \lstinline{Int} and \lstinline{Bool}. In \name
such constraint is specified using an intersection type
\lstinline{Int & Bool}. In general, multiple constraints are specified 
by creating an intersection of all required constraints. 

\paragraph{Type variable constraints}
Disjoint quantification also allows type variables to be disjoint 
to previously defined type variables. For example, the following
program is accepted by \name:
\begin{lstlisting}
let fst A ((*$ \highlight {B *~A} $*)) (x: A & B) : A = x
in (*$ \ldots $*)
\end{lstlisting}
The program has two type variables \lstinline{A} and \lstinline{B}. 
\lstinline{A} is unconstrained and can be instantiated with any type. 
However, the type variable \lstinline{B} can only be instantiated
with types that are disjoint to \lstinline{A}. 
The constraint on \lstinline{B} ensures that the
intersection type \lstinline{A & B} is disjoint for all valid instantiations of $A$ and $B$.
In other words, only coherent uses of \lstinline$fst$ will be accepted.
For example, the following use of \lstinline$fst$:
\begin{lstlisting}
fst Int Char (1,,'c')
\end{lstlisting}
is accepted since \lstinline$Int$ and \lstinline$Char$ are disjoint, thus satisfying the constraint
on the second type parameter of \lstinline$fst$.
Furthermore, problematic uses of \lstinline$fst$, such as:
\begin{lstlisting}
fst Int Int (1,,2)
\end{lstlisting}
\noindent are rejected because \lstinline$Int$ is not disjoint with \lstinline$Int$, thus failing to satisfy the
disjointness constraint on the second type parameter of \lstinline$fst$.

\paragraph{Empty constraint}
%Even though disjoint quantification solves the problem of coherence, there is still one detail 
%that needs further justification.
The type variable $A$ in the \lstinline$fst$ function has no constraint.
In \name this actually means that $A$ should be associated with the empty contraint,
which raises the question: which type should be used to represent such empty constraint?
Or, in other words, which type is disjoint to every other type? 
It is obvious that this type should be one of the bounds of the subtyping lattice: either $\bot$ or
$\top$.
The essential intuition here is that the more specific a type in the subtyping relation is, the less types
exist that are disjoint to it.
For example, $\tyint$ is disjoint to all types except the intersections that contain $\tyint$, $\tyint$
itself, and $\bot$; while $\tyint \inter \tychar$ is disjoint to all types that $\tyint$ is, plus the
types disjoint to $\tychar$.
Thus, the more specific a type variable constraint is, the less options we have to instantiate it with.
This reasoning implies that $\top$ should be treated as the empty constraint.
Indeed, in \name, a single type variable $A$ is only syntactic sugar
for $A * \top$.
\begin{comment}
\joao{should we say anything here about this going against our
  previous top-disjointness formulation?}
\bruno{yes, but not here. We can discuss this in later sections when
  discussing the technical details.}
For instance, the type of the identity function in System $F$ that reads $\forall A. A \to A$ is 
equivalent to the \name's type $\forall (A * \top). A \to A$.
\end{comment}

%Let us assume two distinct interpretations for the subtyping relation.
%Given two types $A$ and $B$, we can say relation is either:
%\begin{enumerate}
%\item Subset relation ($A \subseteq B$): every element of type $A$ is also of type $B$; or
%\item Coercion ($\exists t. t : A \to B$): every element of type $A$ can be coerced into type $B$.
%\end{enumerate}

\begin{comment}
First, if we consider our subtyping lattice as unbounded (i.e. no $\top$ and no $\bot$), then we have that
disjointness is covariant with respect to the subtyping relation.
More formally:
\[ \inferrule {\jwf \Gamma {A \disjoint B} \\ B \subtype C }
              {\jwf \Gamma {A \disjoint C}} \]

To illustrate this, take $A$ as $\tyint$ and $B$ as $\tybool \inter \tychar$.
This lemma states that every supertype of $\tybool \inter \tychar$, namely $\tybool$, $\tychar$ and 
$\tybool \inter \tychar$ itself are also disjoint with $\tyint$.
Coming back to a bounded subtyping lattice, let us now consider both bounds. 
If some type $A$ were to be disjoint with $\bot$, then by the lemma above $A$ will be disjoint to
virtually any type.
This means that, if $A$ is a type variable, then the possible types that it can be instantiated with
are the ones which are disjoint with every other type (otherwise the lemma above will no longer hold).
Clearly $\bot$ is not a suitable option,  
In other words, we can think of $\bot$ as the type as specific as the infinite intersection.
Conversely, $\top$ can be thought as specific - or rather, as general - as the 0-ary intersection.
\end{comment}

%\joao{do we want to say this here?:}
%However, the previous specification of $\top$-disjointness does not reflect this, since it states that $\top$ 
%is not disjoint to any other type, not even to itself.
%Thus, in this paper, we slightly changed the notion of $\top$-disjointness to read instead:

%\begin{definition}[$\top$-disjointness]
%  Two types $A$ and $B$ are disjoint (written $A \disjoint B$) if:
%  \[\forall C.~\text{if}~ A \subtype C~\text{and}~B \subtype C~\text{then}~\toplike{C}\]
%\end{definition}
%\joao{say that we manage to retain coherence wrt to the simply typed version?}

\subsection{Stability of Substitutions}
From the technical point of view, the main challenge in the design of
\name is that, \emph{in general, types are not stable under
substitution}. This contrasts, for example, with System $F$ where types
are stable under substitution. That is in System $F$ the following
property (among others) holds: 

\begin{restatable}[Stability of Substitution]{lemma}{subrefl}
  \label{lemma:subst_stable}
  For any well-formed types $A$ and $B$, and a type variable $\alpha$, the result of substituting 
  $\alpha$ for $A$ in $B$ is also a well-formed type.
\end{restatable}

In \name if a type variable $A$ is substituted in a type $T_1$, for a type $T_2$ 
(written $\subst {T_2} A {T_1}$), where $T_1$ and $T_2$ are well-formed, the resulting type might be 
ill-formed. 
To understand why, recall the previous example: 
\begin{lstlisting}
fst Int Int (1,,2)
\end{lstlisting}
The type signature of \lstinline$fst$ may be read as $\forall A (B * A) . (A \inter B) \to A$.
An application to the type $\tyint$ will lead to instantiation of the variable $A$, leading to the type
$\forall (B * \tyint). (\tyint \inter B) \to \tyint$.
Now, the second $\tyint$ application is problematic, since instantiating $B$ with $\tyint$ will lead to
the ill-formed type $(\tyint \inter \tyint) \to \tyint$.
However, from this example it is easy to see that all types which are not problematic are exactly the
ones disjoint with $A$.
This paper shows how a weaker version of the usual type substituition stability still holds, 
namely by requiring that the type varible's disjointness constraint is compatible
with the type as target of the instantiation. 

\begin{comment}
This section introduces \namedis and its support for intersection types,
parametric polymorphism and the merge operator. It then discusses
the issue of coherence and shows how the notion of disjoint
intersection types and disjoint quantification achieve a coherent semantics.
%Finally we illustrate the expressive power of \namedis by encoding
%extensible type-theoretic encodings of datatypes.

Note that this section uses some syntactic sugar, as well as standard
programming language features, to illustrate the various concepts in
\namedis. Although the minimal core language that we formalize in
Section~\ref{sec:fi} does not present all such features, our implementation
supports them.

%\bruno{Need to type-check the programs!}

%\begin{comment}
%It then shows that,
%with unrestricted intersection types, the system
%lacks \emph{coherence}. This motivates the introduction of
%disjoint intersection types and extending universal quantification to
%disjoint quantification, which is enough to ensure coherence.
%\end{comment}

\subsection{Intersection Types and the Merge Operator}
%%\subsection{Intersection Types, Merge and Polymorphism in \namedis}

Intersection types date back as early as Coppo et
al.'s work~\cite{coppo1981functional}. Since then various researchers have
studied intersection types, and some languages have adopted them in one
form or another.
%However, as we shall see in
%Section~\ref{subsec:incoherence}, it also introduces difficulties. In what follows
%intersection types and the merge operator are informally introduced.

\paragraph{Intersection types.}
The intersection of type $A$ and $B$ (denoted as \lstinline{A & B} in
\namedis) contains exactly those values
which can be used as either values of type $A$ or of type $B$. For instance,
consider the following program in \namedis:

\begin{lstlisting}
let x : Int & Char = (*$ \ldots $*) in -- definition omitted
let idInt (y : Int) : Int = y in
let idChar (y : Char) : Char = y in
(idInt x, idChar x)
\end{lstlisting}

\noindent If a value \lstinline{x} has type \lstinline{Int & Char} then
\lstinline{x} can be used as an integer or as a character. Therefore,
\lstinline{x} can be used as an argument to any function that takes
an integer as an argument, or any
function that take a character as an argument. In the program above
the functions \lstinline{idInt} and \lstinline{idChar} are the
identity functions on integers and characters, respectively.
Passing \lstinline{x} as an argument to either one (or both) of the
functions is valid.

\paragraph{Merge operator.}
In the previous program we deliberately did not show how to introduce values of an
intersection type. There are many variants of intersection types
in the literature. Our work follows a particular formulation, where
intersection types are introduced by a \emph{merge operator}.
As Dunfield~\cite{dunfield2014elaborating} has argued a merge operator adds considerable
expressiveness to a calculus. The merge operator allows
two values to be merged in a single intersection type. For example, an
implementation of \lstinline{x} is constructed in \namedis as follows:

\begin{lstlisting}
let x : Int & Char = 1,,'c' in (*$ \ldots $*)
\end{lstlisting}

\noindent In \namedis (following Dunfield's notation), the
merge of two values $v_1$ and $v_2$ is denoted as $v_1 ,, v_2$.

\paragraph{Merge operator and pairs.}
The merge operator is similar to the introduction construct on pairs.
An analogous implementation of \lstinline{x} with pairs would be:

\begin{lstlisting}
let xPair : (Int, Char) = (1, 'c') in (*$ \ldots $*)
\end{lstlisting}

\noindent The significant difference between intersection types with a
merge operator and pairs is in the elimination construct. With pairs
there are explicit eliminators (\lstinline{fst} and
\lstinline{snd}). These eliminators must be used to extract the
components of the right type. For example, in order to use
\lstinline{idInt} and \lstinline{idChar} with pairs, we would need to
write a program such as:

\begin{lstlisting}
(idInt (fst xPair), idChar (snd xPair))
\end{lstlisting}

\noindent In contrast the elimination of intersection types is done
implicitly, by following a type-directed process. For example,
when a value of type \lstinline{Int} is needed, but an intersection
of type \lstinline{Int & Char} is found, the compiler uses the
type system to extract the corresponding value.

\subsection{Incoherence}\label{subsec:incoherence}
Unfortunatelly the implicit nature of elimination for intersection
types built with a merge operator can lead to incoherence.
The merge operator combines two terms, of type $A$ and $B$
respectively, to form a term of type $A \inter B$. For example,
$1 \mergeop `c'$ is of type $\tyint \inter \tychar$. In this case, no
matter if $1 \mergeop `c'$ is used as $\tyint$ or $\tychar$, the result
of evaluation is always clear. However, with overlapping types, it is
not straightforward anymore to see the result. For example, what
should be the result of this program, which asks for an integer out of
a merge of two integers:
\begin{lstlisting}
(fun (x: Int) (*$ \to $*) x) (1,,2)
\end{lstlisting}
Should the result be \lstinline$1$ or \lstinline$2$?

If both results are accepted, we say that the semantics is
\emph{incoherent}: there are multiple possible meanings for the same
valid program. Dunfield's calculus~\cite{dunfield2014elaborating} is incoherent and accepts the
program above.

\paragraph{Getting around incoherence: biased choice.}
In a real implementation of Dunfield calculus a choice has to be made
on which value to compute. For example, one potential option is to
always take the left-most value matching the type in the
merge. Similarly, one could always take the right-most
value matching the type in the merge. Either way, the meaning
of a program will depend on a biased implementation choice,
which is clearly unsatisfying from the theoretical point of view
(although perhaps acceptable in practice).
Moreover, even if we accept a particular biased choice as
being good enough, the approach cannot be easily
extended to systems with parametric polymorphism, as we illustrate
in Section~\ref{subsec:polymorphism}.

\subsection{Restoring Coherence: Disjoint Intersection Types}\label{sec:restoring}
Coherence is a desirable property for a semantics. A semantics is said
to be coherent if any \emph{valid program} has exactly one
meaning~\cite{reynolds1991coherence} (that is, the semantics is not ambiguous).
One option to restore coherence is to reject programs which may have
multiple meanings.
%Of course, when rejecting programs it is important
%not to be too conservative, and reject too many programs which are
%actually coherent.
Analyzing the expression $1 \mergeop 2$, we can see that the reason
for incoherence is that there are multiple, overlapping, integers in the
merge. Generally speaking, if both terms can be assigned some type $C$,
both of them can be chosen as the meaning of the merge,
which leads to multiple meanings of a term.
Thus a natural option is to try to forbid such overlapping
values of the same type in a merge.

This is precisely the approach taken in \namedis. \namedis requires that the
two types of in intersection must be \emph{disjoint}.  However,
although disjointness seems a natural restriction to impose on
intersection types, it is not obvious to formalize it. Indeed Dunfield
has mentioned disjointness as an option to restore coherence, but he
left it for future work due to the non-triviality of the approach.

\paragraph{Searching for a definition of disjointness.}
The first step towards disjoint intersection types is to come up
with a definition of disjointness. A first attempt at such definition would
be to require that, given two types $A$ and $B$, both types are not
subtypes of each other. Thus, denoting disjointness as $A * B$, we would have:
\[A * B \equiv A \not<: B \wedge B \not<: A\]
At first sight this seems a reasonable definition and it does prevent
merges such as \lstinline{1,,2}. However some moments of thought are enough to realize that
such definition does not ensure disjointness. For example, consider
the following merge:

\begin{lstlisting}
((1,,'c') ,, (2,,True))
\end{lstlisting}

\noindent This merge has two components which are also intersection
types. The first component (\lstinline{(1,,'c')}) has type $\tyint \inter
\tychar$, whereas the second component (\lstinline{(2 ,, True)}) has type
$\tyint \inter \tybool$. Clearly,
\[ \tyint \inter \tychar \not \subtype \tyint \inter \tybool \wedge \tyint \inter \tybool \not \subtype \tyint \inter \tychar \]
Nevertheless the following program still leads to
incoherence:
\begin{lstlisting}
(fun (x: Int) (*$ \to $*) x) ((1,,'c'),,(2,,True))
\end{lstlisting}
as both \lstinline{1} or \lstinline{2} are possible outcomes
of the program. Although this attempt to define disjointness failed,
it did bring us some additional insight: although the types of the two
components of the merge are not subtypes of each other, they share
some types in common.

\paragraph{A proper definition of disjointness.} In order for two types
to be trully disjoint, they must not have any subcomponents sharing
the same type. In a system with intersection types this can be ensured
by requiring the two types do not share a common supertype. The
following definition captures this idea more formally.

\begin{definition}[Disjointness]
  Given two types $A$ and $B$, two types are disjoint
  (written $A \disjoint B$) if there is no type $C$ such that both $A$ and $B$ are
  subtypes of $C$:
  \[A \disjoint B \equiv \not\exists C.~A \subtype C \wedge B \subtype C\]
\end{definition}

\noindent This definition of disjointness prevents the problematic
merge. Since $Int$ is a common supertype of both $Int \& Char$ and
$Int \& Bool$, those two types are not disjoint.

\namedis's type system only accepts programs that use disjoint
intersection types. As shown in Section~\ref{sec:disjoint} disjoint intersection
types will play a crutial rule in guaranteeing that the semantics is coherent.

\subsection{Parametric Polymorphism and Intersection Types}\label{subsec:polymorphism}
Before we show how \namedis extends the idea of disjointness to parametric
polymorphism, we discuss some non-trivial issues that arise from
the interaction between parametric polymorphism and intersection types.
%The interaction between parametric polymorphism and
%intersection types when coherence is a goal is non-trivial.
%In particular biased choice .
%The key challenge is to have a type
%system that still ensures coherence, but at the same time is not too
%restrictive in the programs that can be accepted.
%\begin{comment}
%Dunfield~\cite{} provides a
%good illustrative example of the issues that arise when combining
%disjoint intersection types and parametric polymorphism:
%\[\lambda x. {\bf let}~y = 0 \mergeop x~{\bf in}~x\]
%\end{comment}
Consider the attempt to write
the following polymorphic function in \namedis (we use
uppercase Latin letters to denote type variables):
\begin{lstlisting}
let fst A B (x: A & B) = (fun (z:A) (*$ \to $*) z) x in (*$ \ldots $*)
\end{lstlisting}
The
\code{fst} function is supposed to extract a value of type
(\lstinline{A}) from the merge value $x$ (of type \lstinline{A&B}). However
this function is problematic.  The reason is that when
\lstinline{A} and \lstinline{B} are instantiated to non-disjoint
types, then uses of \lstinline{fst} may lead to incoherence.
For example, consider the following use of \lstinline{fst}:
\begin{lstlisting}
fst Int Int (1,,2)
\end{lstlisting}
\noindent This program is clearly incoherent as both
$1$ and $2$ can be extracted from the merge and still match the type
of the first argument of \lstinline{fst}.

\paragraph{Biased choice breaks equational reasoning.} At first sight, one option
to workaround the issue incoherence would be to bias the type-based merge lookup
to the left or to the right (as discussed in
Section~\ref{subsec:incoherence}). Unfortunately, biased choice is
very problematic when parametric polymorphism is present in the language.
To see the issue, suppose we chose to always pick the
rightmost value in a merge when multiple values of same type exist.
Intuitively, it would appear that the result of the use of
\lstinline{fst} above is $2$. Indeed simple equational reasoning
seems to validate such result:
\begin{lstlisting}
   fst Int Int (1,,2)
(*$ \rightsquigarrow $*) (fun (z: Int) (*$ \to $*) z) (1,,2) -- (* \textnormal{By the definition of \code{fst}} *)
(*$ \rightsquigarrow $*) (fun (z: Int) (*$ \to $*) z) 2      -- (* \textnormal{Right-biased coercion} *)
(*$ \rightsquigarrow $*) 2                          -- (* \textnormal{By $\beta$-reduction} *)
\end{lstlisting}

However (assumming a straightforward implementation of right-biased
choice) the result of the program would be 1! The reason for this has
todo with \emph{when} the type-based lookup on the merge happens. In
the case of \lstinline{fst}, lookup is triggered by a coercion
function inserted in the definition of \lstinline{fst} at
compile-time.
In the definition of \lstinline$fst$ all it is known is that a
value of type $A$ should be returned from a merge with an intersection
type $A\&B$.  Clearly the only type-safe choice to coerce the value of
type $A\&B$ into $A$ is to
take the left component of the merge. This works perfectly for merges
such as \lstinline$(1,,'c')$, where the types of the first and second components
of the merge are disjoint. For the merge \lstinline$(1,,'c')$, if a integer lookup
is needed, then \lstinline$1$ is the rightmost integer, which is consistent with the
biased choice. Unfortunately, when given the merge \lstinline$(1,,2)$ the
left-component (\lstinline$1$) is also picked up, even though in this case \lstinline$2$
is the rightmost integer in the merge. Clearly this is inconsistent
with the biased choice!

Unfortunately this subtle interaction of polymorphism and type-based lookup
 means that equational reasoning is broken!
In the equational reasoning steps above, doing apparently correct
substitutions lead us to a wrong result. This is a major problem for
biased choice and a reason to dismiss it as a possible implementation
choice for \namedis.

\paragraph{Conservatively rejecting intersections.}
To avoid incoherence, and the issues of biased choice, another option
is simply to reject programs where the
instantiations of type variables may lead to incoherent programs.
In this case the definition of \lstinline$fst$ would be rejected, since there
are indeed some cases that may lead to incoherent programs.
Unfortunately this is too restrictive and prevents many useful
programs using both parametric polymorphism and intersection types.
In particular, in the case of \lstinline{fst}, if the two type
parameters are used with two disjoint intersection
types, then the merge will not lead to ambiguity.

In summary, it seems hard to have parametric polymorphism, intersection
types and coherence without being overly conservative.


%\begin{comment}
%\subsection{Intersection Types in Existing Languages}
%
%What is an intersection type? The intersection of types $A$ and $B$
%contains exactly those values which can be used as either of type $A$
%or of type $B$.  Just as not all intersection of sets are nonempty,
%not all intersections of types are inhabited.  For example, the
%intersection of a base type $\tyint$ and a function type
%$\tyint \to \tyint$ is not inhabited.\bruno{put this text somewhere?}
%
%Since then various researchers have
%studied intersection types, and some languages have adopted in one
%form or another. However, while intersection types are already used
%in various languages, the lack of a merge operator removes
%considerable expressiveness.
%
%
%A number of OO languages, such as
%Java, C\#, Scala, and Ceylon\footnote{\url{http://ceylon-lang.org/}},
%already support intersection types to different degrees. Intersection
%types are particularly relevant for OOP as they can be used to model
%multiple interface inheritance. In Java, for example,
%
%\begin{lstlisting}
%interface AwithB extends A, B {}
%\end{lstlisting}
%
%\noindent introduces a new interface \lstinline{AwithB} that satisfies the interfaces of
%both \lstinline{A} and \lstinline{B}. Arguably such type can be considered as a nominal
%intersection type. Scala takes one step further by eliminating the
%need of a nominal type. For example, given two concrete traits, it is possible to
%use \emph{mixin composition} to create an object that implements both
%traits. Such an object has a (structural) intersection type:
%
%\begin{lstlisting}
%trait A
%trait B
%
%val newAB : A with B = new A with B
%\end{lstlisting}
%
%\noindent Scala also allows intersection of type parameters. For example:
%\begin{lstlisting}
%def merge[A,B] (x: A) (y: B) : A with B = ...
%\end{lstlisting}
%uses the anonymous intersection of two type parameters \lstinline{A} and
%\lstinline{B}. However, in Scala it is not possible to dynamically
%compose two objects. For example, the following code:
%
%\begin{lstlisting}
%// Invalid Scala code:
%def merge[A,B] (x: A) (y: B) : A with B = x with y
%\end{lstlisting}
%
%\noindent is rejected by the Scala compiler. The problem is that the
%\lstinline{with} construct for Scala expressions can only be used to
%mixin traits or classes, and not arbitrary objects. Note that in the
%definition \lstinline{newAB} both \lstinline{A} and \lstinline{B} are
%\emph{traits}, whereas in the definition of \lstinline{merge} the variables
%\lstinline{x} and \lstinline{y} denote \emph{objects}.
%
%This limitation essentially put intersection types in Scala in a second-class
%status. Although \lstinline{merge} returns an intersection type, it is
%hard to actually build values with such types. In essence an
%object-level introduction construct for intersection types is missing.
%As it turns out using low-level type-unsafe programming features such
%as dynamic proxies, reflection or other meta-programming techniques,
%it is possible to implement such an introduction
%construct in Scala~\cite{oliveira2013feature,rendel14attributes}. However, this
%is clearly a hack and it would be better to provide proper language
%support for such a feature.
%
%
%
%
%\paragraph{Parametric polymorphism and intersection types.}
%Both universal quantification and intersection types provide a kind of
%polymorphism. While the former provides parametric polymorphism, the latter
%provides ad-hoc polymorphism. In some systems, parametric polymorphism is
%considered the infinite analog of intersection polymorphism. But in our system
%we do not consider this relationship. \george{Need to argue that why their
%coexistence might be a good thing.} \george{May use the merge example}
%\bruno{Some more examples in following subsections?}
%
%
%To address the limitations of intersection types in languages like
%Scala, \namedis allows intersecting any two terms at run time using a
%\emph{merge} operator (denoted by $ \mergeop $)~\cite{dunfield2014elaborating}.  With the merge
%operator it is trivial to implement the \lstinline{merge} function in \namedis:
%
%\begin{lstlisting}
%let merge[A, B * A] (x : A) (y : B) : A & B = x ,, y in (*$ \ldots $*)
%\end{lstlisting}
%
%\noindent In contrast to Scala's term-level \lstinline{with}
%construct, the operator \lstinline{,,} allows two arbitrary values \lstinline{x}
%and \lstinline{y} to be merged. The resulting type is a \emph{disjoint}
%intersection of the types of  \lstinline{x}
%and \lstinline{y} (\lstinline{A & B} in this case).
%
%\paragraph{Incoherence and parametric Polymorphism}
%We can define a \code{fst} function that extracts the first item of a merged value:
%\[
%\code{fst} \ \alpha \ \beta \ (x : \alpha \inter \beta) = \app {(\lam y \alpha y)} x
%\]
%What should be the result of this program?
%\begin{lstlisting}
%fst Int Int (1,,2)
%\end{lstlisting}
%
%Then we have the following equational reasoning:
%\begin{lstlisting}
%fst Int Int (1,,2) => (\(y : Int). y) (1,,2)
%\end{lstlisting}
%If we favor the second item, the program seems to evaluate to $2$. But in
%reality, the result is $2$. No matter we favor the first or the second item,
%we can always construct a program such that for that program, equational
%reasoning is broken.
%
%Therefore, we require that the two types of an intersection must be not
%overlapping, or \emph{disjoint}, and add this requirement to the well-formedness of types.
%
%A well-formed type is such that given any query type,
%it is always clear which subpart the query is referring to.
%In terms of rules, this notion of well-formedness is almost the same as the one in System $F$
%except for intersection types we require the two components to be disjoint.
%
%With parametric polymorphism, disjointness is harder to determine due to type variables.
%Consider this program:
%\[
%\blam \alpha {\lam x {\alpha \inter \tyint} x}
%\]
%$x$ in the body is of type $\alpha \inter \tyint$ and if $\alpha$ and $\tyint$ are
%disjoint depends on the instantiation of $\alpha$.
%\end{comment}

\subsection{Disjoint Quantification}
To avoid being overly conservative, while still retaining coherence in the
presence of parametric polymorphism and intersection types, \namedis uses
an extension to universal quantification called \emph{disjoint quantification}.
Inspired by
bounded quantification~\cite{Cardelli:1994},
where a type variable is constrained by a type
bound, disjoint quantification allows a type variable to be
constrained so that it is disjoint with a
given type. With disjoint quantification a variant of the program $fst$, which
is accepted by \namedis, would be written as:
\begin{lstlisting}
let fst A ((*$ \highlight {B *~A} $*)) (x: A & B) = (fun (z: A) (*$ \to $*) z) x
in (*$ \ldots $*)
\end{lstlisting}
The small change is in the declaration of the type parameter $B$. The notation
$B*A$ means that in this program the type variable $B$ is constrained so that
it can only be instantiated with any type disjoint to $A$.
This ensures that the
merge denoted by $x$ is disjoint for all valid instantiations of $A$ and $B$.

The nice thing about this solution is that many uses of \lstinline$fst$ are accepted.
For example, the following use of \lstinline$fst$:
\begin{lstlisting}
fst Int Char (1,,'c')
\end{lstlisting}
is accepted since \lstinline$Int$ and \lstinline$Char$ are disjoint, thus satisfying the constraint
on the second type parameter of \lstinline$fst$.
However, problematic uses of \lstinline$fst$ are rejected. For example:
\begin{lstlisting}
fst Int Int (1,,2)
\end{lstlisting}
is rejected because \lstinline$Int$ is not disjoint with \lstinline$Int$, thus failing to satisfy the
disjointness constraint on the second type parameter of \lstinline$fst$.

%\begin{comment}
%Note that there is a nice symmetry between bounded quantification and disjoint quantification.
%In systems with bounded quantification,
%the usual unconstrained quantifier $\for {\alpha} \ldots$
%is a syntactic sugar for $\for {\alpha \subtype \top} \ldots$, and
%$\blam \alpha \ldots$ for $\blam {\alpha \subtype \top} \ldots$.
%In parellel, in our system with disjoint quantification,
%the usual unconstrained quantifier $\for {\alpha} \ldots$
%is a syntactic sugar for $\for {\alpha \disjoint \bot} \ldots$, and
%$\blam \alpha \ldots$ for $\blam {\alpha \disjoint \top} \ldots$.
%The intuition is that since the bottom type is akin to the empty set,
%no other type overlaps with it.\george{Format this paragraph better.}
%\end{comment}
%
%
%\begin{comment}
%With this tool in hand, we can rewrite the program above to:
%\[
%\blam {\alpha \disjoint \tyint} {\lam x {\alpha \inter \tyint} x}
%\]
%
%This program typechecks because while $x$ is of type $\alpha \inter \tyint$,
%and $\alpha$ is disjoint with $\tyint$. Similarly, in the new system,
%the original program no longer typechecks, thus preventing overlapping types.
%\end{comment}
\end{comment}
