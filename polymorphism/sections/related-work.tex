\section{Related Work}
\label{sec:related-work}

\paragraph{Coherence}
Reynolds invented Forsythe~\cite{reynolds1997design} in the 1980s. Our
merge operator is analogous to his operator $p_1, p_2 $. Forsythe has
a coherent semantics. The result was proved formally by
Reynolds~\cite{reynolds1991coherence} in a lambda calculus with
intersection types and a merge operator. However there are two key
differences to our work. Firstly the way coherence is ensured is
rather ad-hoc. He has four different typing rules for the merge
operator, each accounting for various possibilities of what the types
of the first and second components are. In some cases the meaning of
the second component takes precedence (that is, is biased) over the
first component. The set of rules is restrictive and it forbids, for
instance, the merge of two functions (even when they a provably
disjoint). In contrast, disjointness in \namedis has a well-defined
specification and it is quite flexible. Secondly, Reynolds calculus
does not support universal quantification. It is unclear to us whether
his set of rules would still ensure disjointness in the presence of
universal quantification. Since some biased choice is allowed in
Reynold's calculus the issues illustrated in Section~\ref{subsec:polymorphism} could be a problem.

Pierce~\cite{pierce1991programming2} made a comprehensive review
of coherence, especially on Curien and Ghelli~\cite{curienl1990coherence} and
Reynolds' methods of proving coherence; but he was not able to prove coherence
for his $F_\wedge$ calculus. He introduced a primitive $\code{glue}$ function as
a language extension which corresponds to our merge operator. However, in his
system users can ``glue'' two arbitrary values, which can lead to incoherence.

Our work is largely inspired by
Dunfield~\cite{dunfield2014elaborating}. He described a similar
approach to ours: compiling a system with intersection types and a
merge operator into
ordinary $ \lambda $-calculus terms with pairs. One major difference
is that his system does not include parametric polymorphism, while
ours does not include unions. The calculus presented in
Section~\ref{sec:fi} can be seen as a relatively straightforward
extension of Dunfield's calculus with parametric
polymorphism. However, as acknowledged by Dunfield, his calculus lacks
of coherence. He discusses the issue of coherence throughout his
paper, mentioning biased choice as an option (albeit a rather
unsatisfying one). He also mentioned that the notion of disjoint
intersection could be a good way to address the problem, but he did not
pursue this option in his work. In contrast to his work, we developed a type
system with disjoint intersection types and proposed disjoint
quantification to guarantee coherence in our calculus.

% \url{http://homepages.inf.ed.ac.uk/gdp/publications/Sub_Par.pdf}

% \cite{plotkin1994subtyping}

% Also discussed intersection types!~\cite{malayeri2008integrating}.

% Pierce Ph.D thesis: F<: + /|
%        technical report: F + /|, closer to ours

% \cite{barbanera1995intersection}

\paragraph{Intersection types with polymorphism.}
Our type system combines intersection types and parametric polymorphism. Closest
to us is Pierce's work~\cite{pierce1991programming1} on a prototype
compiler for a language with both intersection types, union types, and
parametric polymorphism. Similarly to \namedis in his system universal
quantifiers do not support bounded quantification. However Pierce did not try to prove any
meta-theoretical results and his calculus does not have a merge
operator.  Pierce also studied a system where both intersection
types and bounded polymorphism are present in his Ph.D.
dissertation~\cite{pierce1991programming2} and a 1997
report~\cite{pierce1997intersection}.

Going in the direction of higher
kinds, Compagnoni and Pierce~\cite{compagnoni1996higher} added
intersection types to System $ F_{\omega} $ and used the new calculus,
$ F^{\omega}_{\wedge} $, to model multiple inheritance. In their
system, types include the construct of intersection of types of the
same kind $ K $. Davies and Pfenning
\cite{davies2000intersection} studied the interactions between
intersection types and effects in call-by-value languages. And they
proposed a ``value restriction'' for intersection types, similar to
value restriction on parametric polymorphism. Although they proposed a system with
parametric polymorphism, their subtyping rules are significantly different from ours,
since they consider parametric polymorphism
as the ``infinit analog'' of intersection polymorphism.

Recently,
Castagna et al.~\cite{Castagna:2014} studied an very expressive calculus that
has polymorphism and set-theoretic type connectives (such as intersections,
unions, and negations). As a result, in their calculus one is also able to
express a type variable that can be instantiated to any type other than
$\code{Int}$ as $\alpha \setminus \code{Int}$, which is syntactic sugar for
$\alpha \wedge \neg \code{Int}$. As a comparison, such a type will need a
disjoint quantifier, like $\fordis \alpha {\code{Int}} \alpha$, in our system.
Unfortunately their calculus does not include a merge operator like ours.

There have been attempts to provide a foundational calculus
for Scala that incorporates intersection
types~\cite{amin2014foundations,amin2012dependent}.
Although the minimal Scala-like calculus does not natively support
parametric polymorphism, it is possible to encode parametric
polymorphism with abstract type members. Thus it can be argued that
this calculus also supports intersection types and parametric
polymorphism. However, the type-soundness of a minimal Scala-like
calculus with intersection types and parametric polymorphism is not
yet proven. Recently, some form of intersection
types has been adopted in object-oriented languages such as Scala,
Ceylon, and Grace. Generally speaking,
the most significant difference to \namedis is that in all previous systems
there is no explicit introduction construct like our merge operator. As shown in
Section~\ref{subsec:OAs}, this feature is pivotal in supporting modularity
and extensibility because it allows dynamic composition of values.

\begin{comment}
only allow intersections of concrete types (classes),
whereas our language allows intersections of type variables, such as
\texttt{A \& B}. Without that vehicle, we would not be able to define
the generic \texttt{merge} function (below) for all interpretations of
a given algebra, and would incur boilerplate code:

\begin{lstlisting}
let merge [A, B] (f: ExpAlg A) (g: ExpAlg B) = {
  lit (x : Int) = f.lit x ,, g.lit x,
  add (x : A & B) (y : A & B) =
    f.add x y ,, g.add x y
}
\end{lstlisting}
\end{comment}


\paragraph{Other type systems with intersection types.}
% Although similar in spirit,
% our elaboration typing is simpler: we require subtyping in the case of
% applications, thus avoiding the subsumption rule. Besides, our treatment
% combines the merge rules ($ k $ ranges over $ \{1, 2\} $)
% \inferrule
% {\Gamma \turns e_k : A}
% {\Gamma \turns e_1 \mergeop e_2 : A}
% and the standard intersection-introduction rule
% \inferrule
% {\Gamma \turns e : A_1 \andalso \Gamma \turns e : A_2}
% {\Gamma \turns e : A_1 \inter A_2}
% into one rule:
% \inferrule [Merge]
% {\Gamma \turns e_1 : A_1 \andalso \Gamma \turns e_2 : A_2}
% {\Gamma \turns e_1 \mergeop e_2 : A_1 \inter A_2}
%Castagna, and Dunfield describe
%elaborating multi-fields records into merge of single-field records.
% Reynolds and Castagna do not consider elaboration and Dunfield do not
% formalize elaborating records.
% Both Pierce and Dunfield's system include a subsumption rule, which states that
% if an term has been inferred of type $ A $, then it is also of any
% supertype of $ A $. Our system does not have this rule.
Refinement
intersection~\cite{dunfield2007refined,davies2005practical,freeman1991refinement}
is the more conservative approach of adopting intersection types. It increases
only the expressiveness of types but not terms. But without a term-level
construct like ``merge'', it is not possible to encode various language
features. As an alternative to syntactic subtyping described in this paper,
Frisch et al.~\cite{frisch2008semantic} studied semantic subtyping. Semantic
subtyping seems to have important advantages over syntactic subtyping. One
worthy avenue for future work is to study languages with intersection types
and merge operator in a semantic subtyping setting.

\paragraph{Extensibility.} One of our motivations to study systems
with intersections types is to better understand the
type system requirements needed to address extensibility problems.
A well-known problem in programming languages is the Expression
Problem~\cite{wadler1998expression}. In recent years there have been
various solutions to the Expression Problem in the literature. Mostly
the solutions are presented in a specific language, using the language
constructs of that language. For example, in Haskell, type classes~\cite{WadlerB89}
can be used to implement type-theoretic encodings of
datatypes~\cite{Hinze:2006}. It has been shown~\cite{finally-tagless}
that, when encodings of datatypes are modeled with type classes,
the subclassing mechanism of type classes can be used to achieve
extensibility and reuse of operations. Using such techniques provides
a solution to the Expression Problem. Similarly, in OO languages with
generics, it is possible to use generic interfaces and classes to
implement type-theoretic encodings of datatypes. Conventional
subtyping allows the interfaces and classes to be extended, which can
also be used to provide extensibility and reuse of operations. Using
such techniques, it is also possible to solve the Expression Problem
in OO languages~\cite{oliveira09modular,oliveira2012extensibility}.
It is even possible to solve the Expression Problem in theorem provers
like Coq, by exploiting Coq's type class mechanism~\cite{DelawareOS13}.
Nevertheless, although there is a clear connection between all those
techniques and type-theoretic encodings of datatypes, as far as we
know, no one has studied the expression problem from a more
type-theoretic point of view. As shown in Section~\ref{subsec:OAs}, a system
with intersection types, parametric polymorphism, the merge operator
and disjoint quantification can be used to explain type-theoretic
encodings with subtyping and extensibility.


\begin{comment}
To improve support for extensibility various researchers have proposed
new OOP languages or programming mechanisms. It is interesting to
note that design patterns such as object algebras or modular visitors
provide a considerably different approach to extensibility when
compared to some previous proposals for language designs for
extensibility. Therefore the requirements in terms of type system
features are quite different.  One popular approach is \emph{family
  polymorphism}~\cite{Ernst01family}, which allows whole class hierarchies to be
captured as a family of classes. Such a family can be later reused to
create a derived family with potentially new class members, and
additional methods in the existing classes.  \emph{Virtual
  classes}~\cite{ernst2006virtual} are a concrete realization of this idea, where a
container class can hold nested inner \emph{virtual} classes (forming
the family of classes). In a subclass of the container class, the
inner classes can themselves be \emph{overriden}, which is why they
are called virtual. There are many language mechanisms that provide
variants of virtual classes or similar mechanisms~\cite{McDirmid01Jiazzi,Aracic06CaesarJ,Smaragdakis98mixin,nystrom2006j}. The work by
Nystrom on \emph{nested intersection}~\cite{nystrom2006j} uses a
form of intersection types to support the composition of
families of classes. Ostermann's \emph{delegation layers}~\cite{Ostermann02dynamically}
use delegation for doing dynamic composition in a system
with virtual classes. This in contrast with most other approaches
that use class-based composition, but closer to the dynamic
composition that we use in \namedis.
In contrast to type systems for virtual classes
and similar mechanisms, the goal of our work is to study the type
systems and basic language mechanism to better support such design patterns.
 some researchers have designed new type
system features such as virtual classes~\cite{ernst2006virtual}, polymorphic
variants~\cite{garrigue1998programming}, while others have shown employing
programming pattern such as object algebras~\cite{oliveira2012extensibility} by
using features within existing programming languages. Both of the two approaches
have drawbacks of some kind. The first approach often involves heavyweight
designs, while the second approach still sacrifices the readability for
extensibility.
\bruno{fill me in with more details and more references!}
\end{comment}
% Intersection types have been shown to be useful in designing languages that
% support modularity.~\cite{nystrom2006j}

\paragraph{Extensible records.}

\george{Record field deletion is also possible.}

%http://elm-lang.org/learn/Records.elm

Encoding records using intersection types appeared in
Reynolds~\cite{reynolds1997design} and Castagna et al.~\cite{castagna1995calculus}. 
Although Dunfield also discussed this idea in his paper \cite{dunfield2014elaborating}, 
he only provided an implementation but not a formalization. 
Very similar to our treatment of elaborating records is
Cardelli's work~\cite{cardelli1992extensible} on translating a calculus, named
$ F_{\subtype \rho}$, with extensible records to a simpler calculus that without
records primitives (in which case is $ F_{\subtype} $). 
But he did not consider encoding multi-field records as intersections; hence his translation is more
heavyweight. 
Crary~\cite{crary1998simple} used intersection types and
existential types to address the problem that arises when interpreting method
dispatch as self-application. 
But in his paper, intersection types are not used to encode multi-field records.

Wand~\cite{wand1987complete} started the work on extensible records and proposed
row types~\cite{wand1989type} for records. 
Cardelli and Mitchell~\cite{cardelli1990operations} defined three primitive operations on
records that are similar to ours: \emph{selection}, \emph{restriction}, and
\emph{extension}. 
The merge operator in \name plays the same role as extension.
Following Cardelli and Mitchell's approach, of restriction and extension. 
Both Leijen's systems~\cite{leijen2004first,leijen2005extensible} and ours allow records that contain
duplicate labels. 
Leijen's system is more sophisticated. 
For example, it supports passing record labels as arguments to functions. 
He also showed an encoding of intersection types using first-class labels.

% Chlipala's
% \texttt{Ur}~\cite{chlipala2010ur} explains record as type level
% constructs.\bruno{What is the point of citing Chlipala's paper?}

% Our system can be adapted to simulate systems that support extensible
% records but not intersection of ordinary types like \texttt{Int} and
% \texttt{Float} by allowing only intersection of record types.
%
% $ \turnsrec A $ states that $ A $ is a record type, or the intersection of
% record types, and so forth.
%
% \inferrule [RecBase] {} {\turnsrec \recordType l A}
%
% \inferrule [RecStep]
% {\turnsrec A_1 \andalso \turnsrec A_2}
% {\turnsrec A_1 \inter A_2}
%
% \inferrule [Merge']
% {\Gamma \turns e_1 : A_1 \yields {E_1} \andalso \turnsrec A_1 \\
%  \Gamma \turns e_2 : A_2 \yields {E_2} \andalso \turnsrec A_2}
% {\Gamma \turns e_1 \mergeop e_2 : A_1 \inter A_2 \yields {\pair {E_1} {E_2}}}
%
% Of course our approach has its limitation as duplicated labels in a record are
% allowed. This has been discussed in a larger issue by
% Dunfield~\cite{dunfield2014elaborating}.
%
% R{\'e}my~\cite{remy1989type}

\subsection{Extensible records}
\joao{See how to combine this seciton with the previous paragraph}
Our system can be used to encode records, similarly to way as discussed in 
\cite{dunfield2014elaborating}. 
However, describing and implementing records within programming languages is certainly not novel 
and has been extensively studied in the past.
Most of the systems are entirely focused on concrete aspects of records 
(i.e. expressiveness, compilation, etc), while ours piggybacks on the more general notion of  
intersection types.
In this section we aim at comparing our approach with other systems in terms of expressiveness.

Systems with records usually rely on 3 basic operations: selection, restriction and 
extension/concatenation. 
As noted in~\cite{leijen2004first}, systems typically can be categorized into two distinct groups:
the strict and the free.
The former does not allow field overriding when extending a record (i.e. one can only extend a 
record with a field that is not present in it); while the latter does account for field overriding.
Our system can be seen as hybrid of these two kinds of systems.
This will become clear when showing how to encode extension in our system.

\paragraph{Selection}

TODO

\paragraph{Restriction}

\begin{align*}
&\text{remove} :: \fordis \alpha \top {\fordis \beta \top {\fordis r {\recordType l \alpha} 
{({\recordType l \alpha \inter r) \rightarrow r}}}} \\ 
&\text{remove} \, = \blamdis \alpha \top {\blamdis r {\recordType l \alpha} {\lam x {x}}} 
\end{align*}

\paragraph{Extension}

Extension, in a strict system like ..., (polymorphic) extension is achieved in the following manner:

TODO

In ... (SPJ \& MJ) -- a strict system -- an example of a function that makes use of record types 
is the following:
\begin{align*}
&\text{average}_1 :: (r \backslash y, r \backslash x) \Rightarrow \{r | x :: \tyint, y :: \tyint\} \rightarrow \tyint \\
&\text{average}_1 \, r = (r.x + r.y) / 2
\end{align*}

The type signature says that for any record with type $r$, that lacks both $x$ $y$, can be accepted
as parameter extended with $x$ $y$, returning an integer.
Note how the bounded polymorphism is essential to ensure that $r$ does not contain $x$ nor $y$.
On the other hand, in a system with free extension as in~\cite{leijen2005extensible}, 
the more general program would be accepted:

\begin{align*}
&\text{average}_2 :: \forall x \; y, \{ x :: \tyint, y :: \tyint | r \} \rightarrow \tyint \\
&\text{average}_2 \, r = (r.x + r.y) / 2
\end{align*}

In this case, if $r$ contains either field $x$ or field $y$, they would be shadowed by the labels present in the
type signature.
In other words, if a record with multiple $x$ fields, the most recent (i.e. left-most) would be used in 
any function which accesses $x$.

\joao{add example of a system using subtyping}

In \name, such function could be re-written as
\footnote{We do not support exactly this function definition style; 
however the type signature and expression (module infix operators) are exactly as one would write them
in \name}:

\begin{align*}
&\text{average}_3 :: \fordis y \top {\fordis r {\recordType y \tyint} {\recordType y \tyint \inter r \rightarrow \tyint}} \\
&\text{average}_3 = \fordis y \top {\blamdis r {\recordType y \tyint} {(r.x + r.y) / 2}}
\end{align*}

Thus more types are accepted this function than in the first system, but less than the second. 
Since our encoding of records piggybacks on the notion of disjointness, another major difference between
\name and the two other mentioned systems, is the ability to combine records with arbitrary types.
Our system does not account for well-formedness of record types as the other two systems do,

It is also worth noting that systems using subtyping may suffer from the so-called \emph{update} problem.
\joao{show example}

\name does not suffer from this problem.
We may illustrate by defining a suitable update function, similar to the one in~\cite{leijen2005extensible}:

\begin{align*}
&\text{update} :: \fordis \alpha \top {\fordis r {\recordType l \alpha} 
{{\recordType l \alpha \inter r \rightarrow \recordType l \beta \inter r}}} \\ 
&\text{update} \, = \blamdis \alpha \top {\blamdis r {\recordType l \alpha} {\lam x {x}}} 
\end{align*}

\joao{talk about concatenation}

